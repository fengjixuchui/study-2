
<!-- @import "[TOC]" {cmd="toc" depthFrom=1 depthTo=6 orderedList=false} -->

<!-- code_chunk_output -->

- [1. QEMU 的主要工作](#1-qemu-的主要工作)
- [2. 回调函数的注册](#2-回调函数的注册)
- [3. 全局的系统AS和MR的初始化: 不分配GPA/HVA](#3-全局的系统as和mr的初始化-不分配gpahva)
  - [3.1. address_space_init(): 整个AS初始化](#31-address_space_init-整个as初始化)
- [4. 虚拟机实际内存的分配GPA/HVA: 生成RAMBlock添加到ram_list, hva放到host字段](#4-虚拟机实际内存的分配gpahva-生成ramblock添加到ram_listhva放到host字段)
  - [4.1. 分配内存(pc.ram, pc.rom): memory_region_allocate_system_memory](#41-分配内存pcram-pcrom-memory_region_allocate_system_memory)
    - [4.1.1. memory_region_init_ram: 创建ramblock并从host上分配虚拟内存](#411-memory_region_init_ram-创建ramblock并从host上分配虚拟内存)
    - [4.1.2. vmstate_register_ram_global(): ramblock与mr关联](#412-vmstate_register_ram_global-ramblock与mr关联)
  - [4.2. 将整体mr(pc.ram)划分为两个子MR(subregion): 不再申请内存, 即不关联host虚拟内存(HVA)](#42-将整体mrpcram划分为两个子mrsubregion-不再申请内存-即不关联host虚拟内存hva)
    - [4.2.1. 计算above_4g_mem_size和below_4g_mem_size](#421-计算above_4g_mem_size和below_4g_mem_size)
    - [4.2.2. 从pc.ram中划分并加入system_memory的subregion](#422-从pcram中划分并加入system_memory的subregion)
      - [4.2.2.1. memory_region_init_alias(): 初始化alias的mr, 不申请内存](#4221-memory_region_init_alias-初始化alias的mr-不申请内存)
      - [4.2.2.2. memory_region_add_subregion(): subregion注册到全局的system_memory(不是pc.ram)](#4222-memory_region_add_subregion-subregion注册到全局的system_memory不是pcram)
  - [4.3. 提交修改: memory_region_transaction_commit()](#43-提交修改-memory_region_transaction_commit)
    - [4.3.1. address_space_update_topology(): 设置拓扑flatview, 会与KVM交互](#431-address_space_update_topology-设置拓扑flatview-会与kvm交互)
      - [4.3.1.1. generate_memory_topology(mr): 根据给定的mr生成新的Flatview](#4311-generate_memory_topologymr-根据给定的mr生成新的flatview)
      - [4.3.1.2. address_space_set_flatview(): 设置as的FlatView, 会调用KVM](#4312-address_space_set_flatview-设置as的flatview-会调用kvm)
- [5. MEMORY_LISTENER_UPDATE_REGION(): 新FlatRange的更新](#5-memory_listener_update_region-新flatrange的更新)
  - [5.1. kvm_set_phys_mem(): 修改内核内存](#51-kvm_set_phys_mem-修改内核内存)
    - [5.1.1. 属性检查](#511-属性检查)
    - [5.1.2. kvm_align_section(): 得到section/fr的起始地址和大小](#512-kvm_align_section-得到sectionfr的起始地址和大小)
    - [5.1.3. 计算该section/fr对应的主机虚拟机地址(HVA)](#513-计算该sectionfr对应的主机虚拟机地址hva)
    - [5.1.4. kvm_set_user_memory_region(): 转化为slot然后注册到KVM](#514-kvm_set_user_memory_region-转化为slot然后注册到kvm)
- [6. MMIO退出的处理](#6-mmio退出的处理)
- [7. 总结](#7-总结)
- [8. 参考](#8-参考)

<!-- /code_chunk_output -->

# 1. QEMU 的主要工作

内存虚拟化的目的就是让虚拟机能够无缝的访问内存. 有了 **Intel EPT** 的支持后, CPU 在 **VMX non-root** 状态时进行内存访问会**再做一次 EPT 转换**. 在这个过程中, QEMU 会负责以下内容: 

1. 首先需要从**自己的进程地址空间**中**申请内存**用于 **Guest**
2. 需要将上一步中申请到的内存的**虚拟地址(HVA**)和 **Guest 的物理地址**之间的**映射关系**传递给 KVM, 即`GPA->HVA`
3. 需要组织一系列的数据结构来**管理虚拟内存空间**, 并在**内存拓扑结构更改时**将最新的内存信息**同步**至 **KVM** 中

qemu部分的内存申请流程上可以分为三小部分, 分成三小部分主要是我在看代码的时候觉得这三部分耦合性不是很大, 相对而言比较独立. 

众所周知, qemu起始于vl.c中的main函数, 那么这三部分也按照在main函数中的调用顺序分别介绍. 

# 2. 回调函数的注册

涉及函数: `configure_accelerator() --> kvm_init() --> kvm_memory_listener_register() -> memory_listener_register()`

这里所说的accelerator在这里就是kvm, 初始化函数自然调用了`kvm_init`, 该函数主要完成对**kvm的初始化**, 包括一些常规检查如CPU个数、kvm版本等, 还会通过ioctl和内核交互**创建kvm结构**, 这些并非本文重点, 不在赘述. 

在`kvm_init`函数还会调用了`memory_listener_register`

```cpp
    if (kvm_eventfds_allowed) {
        s->memory_listener.listener.eventfd_add = kvm_mem_ioeventfd_add;
        s->memory_listener.listener.eventfd_del = kvm_mem_ioeventfd_del;
    }
    s->memory_listener.listener.coalesced_io_add = kvm_coalesce_mmio_region;
    s->memory_listener.listener.coalesced_io_del = kvm_uncoalesce_mmio_region;
    // 将 address_spaces 与 listener 建立关联
    kvm_memory_listener_register(s, &s->memory_listener,
                                 &address_space_memory, 0);
    memory_listener_register(&kvm_io_listener,
                             &address_space_io);
    memory_listener_register(&kvm_coalesced_pio_listener,
                             &address_space_io);
```

其中`kvm_io_listener`:

```cpp
static MemoryListener kvm_io_listener = {
    .eventfd_add = kvm_io_ioeventfd_add,
    .eventfd_del = kvm_io_ioeventfd_del,
    .priority = 10,
};
```

继而会调用`kvm_memory_listener_register`

```cpp
void kvm_memory_listener_register(KVMState *s, KVMMemoryListener *kml,
                                  AddressSpace *as, int as_id)
{
    int i;

    qemu_mutex_init(&kml->slots_lock);
    kml->slots = g_malloc0(s->nr_slots * sizeof(KVMSlot));
    kml->as_id = as_id;

    for (i = 0; i < s->nr_slots; i++) {
        kml->slots[i].slot = i;
    }
    // 回调函数
    kml->listener.region_add = kvm_region_add;
    kml->listener.region_del = kvm_region_del;
    kml->listener.log_start = kvm_log_start;
    kml->listener.log_stop = kvm_log_stop;
    kml->listener.log_sync = kvm_log_sync;
    kml->listener.log_clear = kvm_log_clear;
    kml->listener.priority = 10;
    // 具体调用
    memory_listener_register(&kml->listener, as);

    for (i = 0; i < s->nr_as; ++i) {
        if (!s->as[i].as) {
            s->as[i].as = as;
            s->as[i].ml = kml;
            break;
        }
    }
}
```

通过`memory_listener_register`函数, 针对**地址空间！！！** 注册了**lisenter**,lisenter本身是**一组函数表**, 当**地址空间发生变化**的时候, 会调用到listener中的相应函数, 从而保持**内核**和**用户空间**的**内存信息的一致性**. 

**虚拟机**包含有**两个地址空间**`address_space_memory`和`address_space_io`, 很容易理解, 正常系统也包含**系统地址空间**和**IO地址空间**. 

`memory_listener_register`函数不复杂, 咱们看下

```cpp
void memory_listener_register(MemoryListener *listener, AddressSpace *filter)
{
    MemoryListener *other = NULL;
    AddressSpace *as;

    listener->address_space_filter = filter;
    /*如果listener为空或者当前listener的优先级大于最后一个listener的优先级, 则可以直接插入*/
    if (QTAILQ_EMPTY(&memory_listeners)
        || listener->priority >= QTAILQ_LAST(&memory_listeners,
                                             memory_listeners)->priority) {
        QTAILQ_INSERT_TAIL(&memory_listeners, listener, link);
    } else {
        /*listener按照优先级升序排列*/
        QTAILQ_FOREACH(other, &memory_listeners, link) {
            if (listener->priority < other->priority) {
                break;
            }
        }
        /*插入listener*/
        QTAILQ_INSERT_BEFORE(other, listener, link);
    }
    /*全局address_spaces-->as*/
    /*对于每个address_spaces, 设置listener*/
    QTAILQ_FOREACH(as, &address_spaces, address_spaces_link) {
        listener_add_address_space(listener, as);
    }
}
```

系统中可以存在**多个listener**, listener之间有着明确的**优先级关系**, 通过**链表**进行组织, **链表头**是**全局**的`memory_listeners`. 

```cpp
static QTAILQ_HEAD(, MemoryListener) memory_listeners
    = QTAILQ_HEAD_INITIALIZER(memory_listeners);
```

函数中, 如果`memory_listeners`为空或者**当前listener**的**优先级**大于最后一个listener的优先级, 即直接把当前listener插入. 否则需要**挨个遍历链表**, 找到**合适的位置**. 具体按照优先级升序查找. 

在函数最后还针对**每个address_space**, 调用`listener_add_address_space`函数, 该函数对其对应的`address_space`管理的**flatrange**向**KVM注册**. 当然, 实际上**此时address_space**尚未经过初始化, 所以这里的循环其实是**空循环**. 

# 3. 全局的系统AS和MR的初始化: 不分配GPA/HVA

涉及函数: `cpu_exec_init_all() -> memory_map_init()` 

在第一节中已经**注册了listener**, 但是**addressspace尚未初始化**, 本节就介绍下其初始化流程. 

从上节的`configure_accelerator()`函数往下走, 会执行`cpu_exec_init_all() -> memory_map_init()`函数, 该函数主要**初始化**了**IO地址空间**和**系统地址空间**. 

Qemu中**系统内存**用**system_memory**来管理, **io内存**用**system_io**来管理. 

原本AS是树状结构, 通过该方式将其展开成平面结构, 最终得到的FlatView相当于一个内存条, 最终生成的结构体间关系如下图所示

![2020-03-11-09-44-30.png](./images/2020-03-11-09-44-30.png)

```cpp
static void memory_map_init(void)
{
    /*为system_memory分配内存*/
    system_memory = g_malloc(sizeof(*system_memory));

    memory_region_init(system_memory, NULL, "system", UINT64_MAX);
    /*初始化全局的address_space_memory*/
    address_space_init(&address_space_memory, system_memory, "memory");

    system_io = g_malloc(sizeof(*system_io));
    memory_region_init_io(system_io, NULL, &unassigned_io_ops, NULL, "io",
                          65536);
    address_space_init(&address_space_io, system_io, "I/O");
}
```

首先MemoryRegion有两种,一种为**纯容器**(逻辑上的概念),一种为**物理内存**(物理内存又有几种: mmio内存. ram, rom, ioport),

地址空间即CPU所能看到的空间, 包括Io空间和memory空间, IO空间使用in、out指令访问, 有回掉函数. Memory空间使用mov等指令访问. 

所以在函数起始, 就对`system_memory`分配了内存, 然后调用了`memory_region_init`函数对其进行初始化, 其中**size**设置为**整个地址空间**: 如果是**64位**就是`2^64`.

## 3.1. address_space_init(): 整个AS初始化

接着调用了`address_space_init`函数对`address_space_memory`进行了初始化. 

```cpp
void address_space_init(AddressSpace *as, MemoryRegion *root, const char *name)
{
    memory_region_ref(root);
    /* 指定address_space_memory的root为system_memory */
    as->root = root;
    as->current_map = NULL;
    as->ioeventfd_nb = 0;
    as->ioeventfds = NULL;
    /* 初始化AddressSpace的listeners链表 */
    QTAILQ_INIT(&as->listeners);
    /* 把address_space_memory插入全局链表 */
    QTAILQ_INSERT_TAIL(&address_spaces, as, address_spaces_link);
    /* AddressSpace的名称 */
    as->name = g_strdup(name ? name : "anonymous");
    // 初始化对应的 flatview, 设置拓扑
    address_space_update_topology(as);
    address_space_update_ioeventfds(as);
}
```

函数主要做了以下几个工作, 设置**addressSpaceh和MR的关联**, 设置**其名称**, 把`address_space_memory`加入到**全局的address_spaces链表**中, 并通过`address_space_update_topology(as)`**初始化对应的FlatView**, 在这个里面会调用`MEMORY_LISTENER_UPDATE_REGION()`**提交本次修改**, 这个后面做论述. 

`address_space_update_topology()`调用下面会分析.

回到`memory_map_init()`函数中, 接下来按照同样的模式对IO区域`system_io`和IO地址空间`address_space_io`做了初始化. 

针对系统内核、系统IO的MR和AS的初始化,  但是并不分配GPA/HVA, MR和AS都是全局的

# 4. 虚拟机实际内存的分配GPA/HVA: 生成RAMBlock添加到ram_list, hva放到host字段

前面**注册listener**也好, 或是初始化addressspace也好, 实际上均**没有对应的物理内存**. 

顺着main往下走, 会调用到`machine—>init`, 实际上对应于`pc_init_pci`函数, 在虚拟机的创建与运行中`pc_init_pci`负责在**qemu中初始化虚拟机**, **内存初始化**也是在这里完成的, 还是一步步从qemu说起, 在vl.c的main函数中有`ram_size`参数, 由qemu入参标识`QEMU_OPTION_m`设定, 顾名思义就是**虚拟机内存的大小**, 通过`machine->init`一步步传递给`pc_init1`函数. 在这里分出了`above_4g_mem_size`和`below_4g_mem_size`, 即**高低端内存**(也**不一定是32bit机器**..), 然后开始**初始化内存**, 即`pc_memory_init`, 内存通过`memory_region_init_ram`下面的`qemu_ram_alloc`分配, 使用`qemu_ram_alloc_from_ptr`. 

我们直接从`pc_memory_init()`函数开始

```cpp
void pc_memory_init(PCMachineState *pcms,
                    MemoryRegion *system_memory,
                    MemoryRegion *rom_memory,
                    MemoryRegion **ram_memory)
{
    int linux_boot, i;
    MemoryRegion *ram, *option_rom_mr;
    MemoryRegion *ram_below_4g, *ram_above_4g;
    FWCfgState *fw_cfg;
    MachineState *machine = MACHINE(pcms);
    MachineClass *mc = MACHINE_GET_CLASS(machine);
    PCMachineClass *pcmc = PC_MACHINE_GET_CLASS(pcms);
    X86MachineState *x86ms = X86_MACHINE(pcms);

    assert(machine->ram_size == x86ms->below_4g_mem_size +
                                x86ms->above_4g_mem_size);

    linux_boot = (machine->kernel_filename != NULL);

    /* Allocate RAM.  We allocate it as a single memory region and use
     * aliases to address portions of it, mostly for backwards compatibility
     * with older qemus that used qemu_ram_alloc().
     */
    /* 分配新的整体MR */
    ram = g_malloc(sizeof(*ram));
    /* 根据虚拟机内存大小初始化MR, 为其分配具体的内存, 将mr->name设进block */
    memory_region_allocate_system_memory(ram, NULL, "pc.ram",
                                         machine->ram_size);
    *ram_memory = ram;
    ram_below_4g = g_malloc(sizeof(*ram_below_4g));
    // 对前面的整体mr(pc.ram)进行划分
    memory_region_init_alias(ram_below_4g, NULL, "ram-below-4g", ram,
                             0, x86ms->below_4g_mem_size);
    // 将mr(ram_below_4g)加入全局mr(system_memory)的子mr
    memory_region_add_subregion(system_memory, 0, ram_below_4g);
    e820_add_entry(0, x86ms->below_4g_mem_size, E820_RAM);
    if (x86ms->above_4g_mem_size > 0) {
        ram_above_4g = g_malloc(sizeof(*ram_above_4g));
        memory_region_init_alias(ram_above_4g, NULL, "ram-above-4g", ram,
                                 x86ms->below_4g_mem_size,
                                 x86ms->above_4g_mem_size);
        memory_region_add_subregion(system_memory, 0x100000000ULL,
                                    ram_above_4g);
        e820_add_entry(0x100000000ULL, x86ms->above_4g_mem_size, E820_RAM);
    }

    if (!pcmc->has_reserved_memory &&
        (machine->ram_slots ||
         (machine->maxram_size > machine->ram_size))) {

        error_report("\"-memory 'slots|maxmem'\" is not supported by: %s",
                     mc->name);
        exit(EXIT_FAILURE);
    }
    /* always allocate the device memory information */
    machine->device_memory = g_malloc0(sizeof(*machine->device_memory));

    /* initialize device memory address space */
    if (pcmc->has_reserved_memory &&
        (machine->ram_size < machine->maxram_size)) {
        ram_addr_t device_mem_size = machine->maxram_size - machine->ram_size;

        if (machine->ram_slots > ACPI_MAX_RAM_SLOTS) {
            error_report("unsupported amount of memory slots: %"PRIu64,
                         machine->ram_slots);
            exit(EXIT_FAILURE);
        }

        if (QEMU_ALIGN_UP(machine->maxram_size,
                          TARGET_PAGE_SIZE) != machine->maxram_size) {
            error_report("maximum memory size must by aligned to multiple of "
                         "%d bytes", TARGET_PAGE_SIZE);
            exit(EXIT_FAILURE);
        }

        machine->device_memory->base =
            ROUND_UP(0x100000000ULL + x86ms->above_4g_mem_size, 1 * GiB);

        if (pcmc->enforce_aligned_dimm) {
            /* size device region assuming 1G page max alignment per slot */
            device_mem_size += (1 * GiB) * machine->ram_slots;
        }

        if ((machine->device_memory->base + device_mem_size) <
            device_mem_size) {
            error_report("unsupported amount of maximum memory: " RAM_ADDR_FMT,
                         machine->maxram_size);
            exit(EXIT_FAILURE);
        }

        memory_region_init(&machine->device_memory->mr, OBJECT(pcms),
                           "device-memory", device_mem_size);
        memory_region_add_subregion(system_memory, machine->device_memory->base,
                                    &machine->device_memory->mr);
    }
    /* Initialize PC system firmware */
    pc_system_firmware_init(pcms, rom_memory);

    option_rom_mr = g_malloc(sizeof(*option_rom_mr));
    memory_region_init_ram(option_rom_mr, NULL, "pc.rom", PC_ROM_SIZE,
                           &error_fatal);
    if (pcmc->pci_enabled) {
        memory_region_set_readonly(option_rom_mr, true);
    }
    memory_region_add_subregion_overlap(rom_memory,
                                        PC_ROM_MIN_VGA,
                                        option_rom_mr,
                                        1);

    fw_cfg = fw_cfg_arch_create(machine,
                                x86ms->boot_cpus, x86ms->apic_id_limit);

    rom_set_fw(fw_cfg);

    if (pcmc->has_reserved_memory && machine->device_memory->base) {
        uint64_t *val = g_malloc(sizeof(*val));
        PCMachineClass *pcmc = PC_MACHINE_GET_CLASS(pcms);
        uint64_t res_mem_end = machine->device_memory->base;

        if (!pcmc->broken_reserved_end) {
            res_mem_end += memory_region_size(&machine->device_memory->mr);
        }
        *val = cpu_to_le64(ROUND_UP(res_mem_end, 1 * GiB));
        fw_cfg_add_file(fw_cfg, "etc/reserved-memory-end", val, sizeof(*val));
    }

    if (linux_boot) {
        x86_load_linux(x86ms, fw_cfg, pcmc->acpi_data_size,
                       pcmc->pvh_enabled, pcmc->linuxboot_dma_enabled);
    }

    for (i = 0; i < nb_option_roms; i++) {
        rom_add_option(option_rom[i].name, option_rom[i].bootindex);
    }
    x86ms->fw_cfg = fw_cfg;

    /* Init default IOAPIC address space */
    x86ms->ioapic_as = &address_space_memory;

    /* Init ACPI memory hotplug IO base address */
    pcms->memhp_io_base = ACPI_MEMORY_HOTPLUG_BASE;
}
```

从总体上来讲, 该函数主要完成了三个工作: 

1. 为pc.ram和pc.rom都生成新的MR, 并**分配内存**(一整个memory region)

2. 然后根据`below_4g_mem_size`、`above_4g_mem_size`分别对**pc.ram进行划分**, 形成**子MR**, 并注册**子MR**到**root MR system_memory 的subregions链表**中. 

3. 最后需要调用`memory_region_transaction_commit()`函数提交修改.

## 4.1. 分配内存(pc.ram, pc.rom): memory_region_allocate_system_memory

为虚拟机内存"pc.ram"和"pc.rom"都分别生成了新的MR, 然后分配内存, 这里看"pc.ram"的内存分配`memory_region_allocate_system_memory(ram, NULL, "pc.ram", machine->ram_size);`, 对于非大页最终会调用到函数`memory_region_init_ram_shared_nomigrate()`

```cpp
memory_region_allocate_system_memory()
    allocate_system_memory_nonuma()
    | └- memory_region_init_ram_shared_nomigrate()
    └- vmstate_register_ram_global();
```

### 4.1.1. memory_region_init_ram: 创建ramblock并从host上分配虚拟内存

qemu对内存条的模拟管理, 是通过`RAMBlock`和`ram_list`管理的, **RAMBlock**就是**每次申请的内存池**, `ram_list`则是RAMBlock的**链表**

```cpp
void memory_region_init_ram_shared_nomigrate(MemoryRegion *mr,
                                             Object *owner,
                                             const char *name,
                                             uint64_t size,
                                             bool share,
                                             Error **errp)
{
    Error *err = NULL;
    // 这个mr就是为系统内存重新分配的, 这里只是初始化
    memory_region_init(mr, owner, name, size);
    // 是ram
    mr->ram = true;
    // 不是纯容器
    mr->terminates = true;
    mr->destructor = memory_region_destructor_ram;
    // 分配了具体的内存, 主机虚拟内存, 返回RAMBlock
    mr->ram_block = qemu_ram_alloc(size, share, mr, &err);
    mr->dirty_log_mask = tcg_enabled() ? (1 << DIRTY_MEMORY_CODE) : 0;
    if (err) {
        mr->size = int128_zero();
        object_unparent(OBJECT(mr));
        error_propagate(errp, err);
    }
}
```

该函数实现很简单, 首先调用`memory_region_init`对**MR**做**初始化**. 

然后进行简单的设置, 最重要的还是最后的`qemu_ram_alloc`, 最终调用`qemu_ram_alloc_internal(size, size, NULL, NULL, false, share, mr, errp)`

```cpp
// exec.c
static
RAMBlock *qemu_ram_alloc_internal(ram_addr_t size, ram_addr_t max_size,
                                  void (*resized)(const char*,
                                                  uint64_t length,
                                                  void *host),
                                  void *host, bool resizeable, bool share,
                                  MemoryRegion *mr, Error **errp)
{
    RAMBlock *new_block;
    Error *local_err = NULL;
    // 根据主机页面对齐
    size = HOST_PAGE_ALIGN(size);
    max_size = HOST_PAGE_ALIGN(max_size);
    // RAMBlock 生成
    new_block = g_malloc0(sizeof(*new_block));
    // 指向pc.ram/pc.rom
    new_block->mr = mr;
    // NULL
    new_block->resized = resized;
    // 已使用长度, 等于
    new_block->used_length = size;
    new_block->max_length = max_size;
    assert(max_size >= size);
    // 映射文件描述符
    new_block->fd = -1;
    // 页面大小
    new_block->page_size = qemu_real_host_page_size;
    // 这里是NULL
    new_block->host = host;
    if (host) {
        new_block->flags |= RAM_PREALLOC;
    }
    if (resizeable) {
        new_block->flags |= RAM_RESIZEABLE;
    }
    // 添加该ramblock, 里面从host上分配内存
    ram_block_add(new_block, &local_err, share);
    if (local_err) {
        g_free(new_block);
        error_propagate(errp, local_err);
        return NULL;
    }
    return new_block;
}

static void ram_block_add(RAMBlock *new_block, Error **errp, bool shared)
{
    RAMBlock *block;
    RAMBlock *last_block = NULL;
    ram_addr_t old_ram_size, new_ram_size;
    Error *err = NULL;

    old_ram_size = last_ram_page();

    qemu_mutex_lock_ramlist();
    // 在虚拟机物理地址空间的偏移
    // 在虚拟机物理地址空间分配空间
    new_block->offset = find_ram_offset(new_block->max_length);
    // 还没分配, 所以会进入
    if (!new_block->host) {
        if (xen_enabled()) {
            xen_ram_alloc(new_block->offset, new_block->max_length,
                          new_block->mr, &err);
            if (err) {
                error_propagate(errp, err);
                qemu_mutex_unlock_ramlist();
                return;
            }
        } else {
            // 在host上分配虚拟内存, 其实就是alloc()函数
            new_block->host = phys_mem_alloc(new_block->max_length,
                                             &new_block->mr->align, shared);
            if (!new_block->host) {
                error_setg_errno(errp, errno,
                                 "cannot set up guest memory '%s'",
                                 memory_region_name(new_block->mr));
                qemu_mutex_unlock_ramlist();
                return;
            }
            // 与相邻的block合并
            memory_try_enable_merging(new_block->host, new_block->max_length);
        }
    }

    new_ram_size = MAX(old_ram_size,
              (new_block->offset + new_block->max_length) >> TARGET_PAGE_BITS);
    if (new_ram_size > old_ram_size) {
        dirty_memory_extend(old_ram_size, new_ram_size);
    }
    /* Keep the list sorted from biggest to smallest block.  Unlike QTAILQ,
     * QLIST (which has an RCU-friendly variant) does not have insertion at
     * tail, so save the last element in last_block.
     */
    RAMBLOCK_FOREACH(block) {
        last_block = block;
        if (block->max_length < new_block->max_length) {
            break;
        }
    }
    if (block) {
        QLIST_INSERT_BEFORE_RCU(block, new_block, next);
    } else if (last_block) {
        QLIST_INSERT_AFTER_RCU(last_block, new_block, next);
    } else { /* list is empty */
        QLIST_INSERT_HEAD_RCU(&ram_list.blocks, new_block, next);
    }
    ram_list.mru_block = NULL;

    /* Write list before version */
    smp_wmb();
    ram_list.version++;
    qemu_mutex_unlock_ramlist();

    cpu_physical_memory_set_dirty_range(new_block->offset,
                                        new_block->used_length,
                                        DIRTY_CLIENTS_ALL);

    if (new_block->host) {
        qemu_ram_setup_dump(new_block->host, new_block->max_length);
        // 使用madvise对内存使用限定
        qemu_madvise(new_block->host, new_block->max_length, QEMU_MADV_HUGEPAGE);
        /* MADV_DONTFORK is also needed by KVM in absence of synchronous MMU */
        qemu_madvise(new_block->host, new_block->max_length, QEMU_MADV_DONTFORK);
        ram_block_notify_add(new_block->host, new_block->max_length);
    }
}
```

咱们重点看下这个函数, 该函数围绕**RAMBlock结构**, 在函数起始对**size进行页对齐**, 然后**申请一个RAMBlock结构**, 之后对其字段进行一些设置如**指定MR** 和offset, **offset**理论上需要调用`find_ram_offset`在已有的**RAMBlock**中找到一个可用的. 但是此时实际上**还没有其他block**, 所以这里应该**直接返回0**的. 

![2020-02-29-18-57-01.png](./images/2020-02-29-18-57-01.png)

上图是qemu模拟的普通内存分布模型, 内存的线性也是分块被使用的, 每个块称为RAMBlock, 由ram_list统领, RAMBlock.offset则是区块的线性地址, 即相对于开始的偏移位, RAMBlock.length(size)则是区块的大小. `find_ram_offset`函数则是在**线性区间内**找到**没有使用的一段空间**, 可以完全容纳**新申请的ramblock length大小**, 代码就是进行了所有区块的遍历(全局链表`ram_list`), 找到满足新申请length的最小区间, 把ramblock安插进去即可, 返回的offset即是新分配区间的开始地址. 

本部分最重要的莫过于**设置其host**了, 其对应的**宿主机虚拟地址空间！！！** 的**虚拟地址**. 在支持**大页**的情况下调用`file_ram_alloc()`函数进行分配, 否则调用`phys_mem_alloc()`函数进行分配. 二者分配其实都是利用**mmap**分配的, 但是在支持大页的情况下需要传递参数`mem_path`,所以需要两个函数. 

在**非大页**的情况下, 分配好内存尝试**和相邻的block合并**下. 

最后把block插入到**全局的链表**`ram_list`中, 只是block保持**从大到小**的顺序. 

### 4.1.2. vmstate_register_ram_global(): ramblock与mr关联

```cpp
void vmstate_register_ram_global(MemoryRegion *mr)
{
    vmstate_register_ram(mr, NULL);
}

void vmstate_register_ram(MemoryRegion *mr, DeviceState *dev)
{
    qemu_ram_set_idstr(mr->ram_block,
                       memory_region_name(mr), dev);
    qemu_ram_set_migratable(mr->ram_block);
}
```

`vmstate_register_ram_global`这个函数则是负责将前面提到的ramlist中的**ramblock**和**memory region**的初始地址对应一下, 将`mr->name`填充到ramblock的**idstr**里面, 就是让二者有确定的对应关系, 如此**mr**就有了**物理内存**使用. 

## 4.2. 将整体mr(pc.ram)划分为两个子MR(subregion): 不再申请内存, 即不关联host虚拟内存(HVA)

此时`pc.ram`已经分配完成, `ram_addr`已经拿到了分配的内存地址, MemoryRegion ram初始化完成. 

在创建好了ram并且分配好了空间之后, 创建了**两个mr alias**, `ram_below_4g`以及`ram_above_4g`, 这两个mr分别指向**ram的低4g**以及**高4g空间**, 这两个alias是挂在**根system\_memory mr下面**的, 即高低端内存(也不一定是32bit机器)

然后将`memory_region_add_subregion`添加**关联起来**.

### 4.2.1. 计算above_4g_mem_size和below_4g_mem_size

对于 `x86_64`, 需要给system io留0.5G内存, 检查虚拟机内存是否大于4G(ram_size是否大于3.5G), 计算如下

```cpp
PCMAchineState *pcms;
X86MachineState *x86ms = X86_MACHINE(pcms);

pc_init1()
    if (machine->ram_size >= 0xe0000000) {
        lowmem = gigabyte_align ? 0xc0000000 : 0xe0000000;
    } else {
        lowmem = 0xe0000000;
    }

    if (machine->ram_size >= lowmem) {
        above_4g_mem_size = machine->ram_size - lowmem;
        below_4g_mem_size = lowmem;
    } else {
        above_4g_mem_size = 0;
        below_4g_mem_size = machine->ram_size;
    }
```

其中 0xc0000000 为 3G, 0xe0000000 为 3.5G; 总之, 无论是否32位机器

- 内存大于3.5G, `below_4g_mem_size = 3G`, `above = size - 3G`;
- 内存小于3.5G, `below_4g_mem_size = size`, `above = 0`;


### 4.2.2. 从pc.ram中划分并加入system_memory的subregion

```cpp
    // 创建新的 mr
    MemoryRegion *ram_below_4g = g_malloc(sizeof(*ram_below_4g));
    // 对前面的整体mr(pc.ram)进行划分
    memory_region_init_alias(ram_below_4g, NULL, "ram-below-4g", ram,
                             0, x86ms->below_4g_mem_size);
    // 将mr(ram_below_4g)加入全局mr(system_memory)的子mr
    memory_region_add_subregion(system_memory, 0, ram_below_4g);
    e820_add_entry(0, x86ms->below_4g_mem_size, E820_RAM);
    if (x86ms->above_4g_mem_size > 0) {
        MemoryRegion *ram_above_4g = g_malloc(sizeof(*ram_above_4g));
        memory_region_init_alias(ram_above_4g, NULL, "ram-above-4g", ram,
                                 x86ms->below_4g_mem_size,
                                 x86ms->above_4g_mem_size);
        memory_region_add_subregion(system_memory, 0x100000000ULL,
                                    ram_above_4g);
        e820_add_entry(0x100000000ULL, x86ms->above_4g_mem_size, E820_RAM);
    }
```

#### 4.2.2.1. memory_region_init_alias(): 初始化alias的mr, 不申请内存

`memory_region_init_alias()`函数便对**两个子MR进行初始化**, 这里就**不再进行内存的申请**, 主要是设置`alias`和`alias_offset`字段, 代码如下. 

```cpp
void memory_region_init_alias(MemoryRegion *mr,
                              Object *owner,
                              const char *name,
                              MemoryRegion *orig,
                              hwaddr offset,
                              uint64_t size)
{
    memory_region_init(mr, owner, name, size);
    // 这里就是 pc.ram 的MR
    mr->alias = orig;
    // 这里就是相对于 pc.ram 的偏移
    mr->alias_offset = offset;
}
```

12月16日

#### 4.2.2.2. memory_region_add_subregion(): subregion注册到全局的system_memory(不是pc.ram)

在初始化完毕, 需要调用`memory_region_add_subregion()`函数把**子MR**注册到**全局的system_memory**. 该函数实现是比较简单的, 但是需要重点介绍下, 因为这里执行了关键的更新操作. 

```cpp
memory_region_add_subregion(system_memory, 0, ram_below_4g);
memory_region_add_subregion(system_memory, 0x100000000ULL, ram_above_4g);

void memory_region_add_subregion(MemoryRegion *mr,
                                 hwaddr offset,
                                 MemoryRegion *subregion)
{
    // 优先级
    subregion->priority = 0;
    memory_region_add_subregion_common(mr, offset, subregion);
}
```

函数核心交给`memory_region_add_subregion_common()`函数实现

```cpp
static void memory_region_add_subregion_common(MemoryRegion *mr,
                                               hwaddr offset,
                                               MemoryRegion *subregion)
{
    assert(!subregion->container);
    // container为system_memory
    subregion->container = mr;
    // addr 是在父MR中的偏移, GPA
    subregion->addr = offset;
    memory_region_update_container_subregions(subregion);
}
```

该函数同样比较简单, 设置`subregion->container`和`system_memory`的关联, 设置**其addr字段**为offset, 即在**全局AS中的偏移**. 

```cpp
static void memory_region_update_container_subregions(MemoryRegion *subregion)
{
    MemoryRegion *mr = subregion->container;
    MemoryRegion *other;

    memory_region_transaction_begin();

    memory_region_ref(subregion);
    QTAILQ_FOREACH(other, &mr->subregions, subregions_link) {
        if (subregion->priority >= other->priority) {
            QTAILQ_INSERT_BEFORE(other, subregion, subregions_link);
            goto done;
        }
    }
    QTAILQ_INSERT_TAIL(&mr->subregions, subregion, subregions_link);
done:
    memory_region_update_pending |= mr->enabled && subregion->enabled;
    memory_region_transaction_commit();
}
```

然后就按照**优先级顺序**把**subregion**插入到`system_memory`的**subregions链表**中, 这些都比较简单.

目前我们添加了区域, **地址空间已经发生变化**, 自然要把变化和KVM进行同步, 这一工作由`memory_region_transaction_commit()`实现. 

## 4.3. 提交修改: memory_region_transaction_commit()

```cpp
void memory_region_transaction_commit(void)
{
    AddressSpace *as;

    assert(memory_region_transaction_depth);
    --memory_region_transaction_depth;
    if (!memory_region_transaction_depth && memory_region_update_pending) {
        memory_region_update_pending = false;
        MEMORY_LISTENER_CALL_GLOBAL(begin, Forward);
        /*更新各个addressspace 拓扑结构*/
        QTAILQ_FOREACH(as, &address_spaces, address_spaces_link) {
            address_space_update_topology(as);
        }

        MEMORY_LISTENER_CALL_GLOBAL(commit, Forward);
    }
}
```

可以看到, 这里listener的作用就凸显出来了. 

对于**每个address_space！！！**, 调用`address_space_update_topology()`执行更新. 

### 4.3.1. address_space_update_topology(): 设置拓扑flatview, 会与KVM交互

这个在`address_space_init()`时候也会调用, 当`address_space_memory`调用时, mr就是`system_memory`

```cpp
static void address_space_update_topology(AddressSpace *as)
{
    // 获取as的mr, 如果是alias, 使用原始mr
    MemoryRegion *physmr = memory_region_get_flatview_root(as->root);

    flatviews_init();
    // 在哈希表flat_views中根据physmr(key)查找这个view, 如果不存在, 生成新的 flatview
    if (!g_hash_table_lookup(flat_views, physmr)) {
        // 核心函数, 基于root MR生成 flatview
        generate_memory_topology(physmr);
    }
    // 更新as的flatview
    address_space_set_flatview(as);
}
```

里面涉及两个重要的函数`generate_memory_topology`和`address_space_update_topology_pass`. 

前者对于**一个给定的MR**, 生成其**对应的FlatView**, 而后者则根据**oldview**和**newview**对当前视图进行更新. 

#### 4.3.1.1. generate_memory_topology(mr): 根据给定的mr生成新的Flatview

```cpp
/* Render a memory topology into a list of disjoint absolute ranges. */
static FlatView *generate_memory_topology(MemoryRegion *mr)
{
    int i;
    FlatView *view;

    /* 根据AddressSpace对应的MR生成一个新的FlatView */
    view = flatview_new(mr);

    if (mr) {
        /*
          * 将mr所管理的内存进行平坦展开为FlatView,通过view返回
          * addrrange_make(int128_zero(), int128_2_64()) --> 指定一个GUEST内存空间, 起始GPA等于0, 大小等于2^64, 可以想象成GUEST的整个物理地址空间
          */
        render_memory_region(view, mr, int128_zero(),
                             addrrange_make(int128_zero(), int128_2_64()),
                             false, false);
    }
    /* 简化FlatView, 将View中的FlatRange能合并的都合并 */
    flatview_simplify(view);
    // dispatch 负责根据 GPA 找到 HVA
    view->dispatch = address_space_dispatch_new(view);
    for (i = 0; i < view->nr; i++) {
        MemoryRegionSection mrs =
            section_from_flat_range(&view->ranges[i], view);
        flatview_add_to_dispatch(view, &mrs);
    }
    address_space_dispatch_compact(view->dispatch);
    // 更新flatview的哈希表 flat_views
    g_hash_table_replace(flat_views, mr, view);

    return view;
}

static FlatView *flatview_new(MemoryRegion *mr_root)
{
    FlatView *view;
    // 新分配一个FlatView并初始化
    view = g_new0(FlatView, 1);
    // 引用计数
    view->ref = 1;
    // 该FlatView的root指向对应的MR
    view->root = mr_root;
    memory_region_ref(mr_root);
    trace_flatview_new(view, mr_root);
    return view;
}
```

调用`render_memory_region()`:

- 函数的参数为 `FlatView *view`, 代表线性空间视图,维护**MemoryRegion**和 **线性地址**的关系(用于**gpa→hva**的转换)

- `MemoryRegion *mr` 则为要渲染的MemoryRegion
- base 标示该MemoryRegion对应最根层MemoryRegion的偏移(最根层的偏移一般为0 ,现在已知的就 system_memory 和 system_io两个地址空间, 分别代表内存空间和io空间), 这里为0, GPA
- clip 表示**父空间的地址范围**, 子空间的地址范围是不允许落在父空间的范围外的, 如第一次render时clip代表了整个虚拟机物理地址空间

```cpp
(AddrRange){0, 2^64};
```

```cpp
/* Render a memory region into the global view.  Ranges in @view obscure
 * ranges in @mr.
 */
static void render_memory_region(FlatView *view,
                                 MemoryRegion *mr,
                                 Int128 base,
                                 AddrRange clip,
                                 bool readonly,
                                 bool nonvolatile)
{
    MemoryRegion *subregion;
    unsigned i;
    // 在region中的偏移
    hwaddr offset_in_region;
    // 待展开的内存的长度
    Int128 remain;
    // 本次展开的长度或跳过的长度
    Int128 now;
    FlatRange fr;
    AddrRange tmp;

    if (!mr->enabled) {
        return;
    }
    // base
    // mr的addr什么时候初始化的?
    // base改为MR的起始地址, addr实际上是subregion在父mr中的偏移, base = base + mr->addr
    int128_addto(&base, int128_make64(mr->addr));
    //它的读写模式就是mr的读写模式
    readonly |= mr->readonly;
    nonvolatile |= mr->nonvolatile;
    // 返回base以及大小即start&size, {0, 2^64}
    // 当前mr的地址空间范围
    tmp = addrrange_make(base, mr->size);
    //计算结果true因此不执行这里. 继续向下执行
    // 判断目标MR与clip是否有交叉, 即MR应该落在clip的范围内
    if (!addrrange_intersects(tmp, clip)) {
        return;
    }
    // 缩小clip到交叉的部分
    //结果为start=0, size=0xffffffffffffffffui64
    clip = addrrange_intersection(tmp, clip);
    // 对别名空间进行渲染
    // 子区域才有alias
    if (mr->alias) {
        int128_subfrom(&base, int128_make64(mr->alias->addr));
        int128_subfrom(&base, int128_make64(mr->alias_offset));
        //以上两行的计算得出别名空间的大小, 然后渲染别名空间
        render_memory_region(view, mr->alias, base, clip,
                             readonly, nonvolatile);
        return;
    }
    // //渲染子region
    /* Render subregions in priority order. */
    QTAILQ_FOREACH(subregion, &mr->subregions, subregions_link) {
        render_memory_region(view, subregion, base, clip,
                             readonly, nonvolatile);
    }
    //teminates为false表示该容器为纯容器只需要渲染不需要生成flatrange
    if (!mr->terminates) {
        return;
    }
    //计算Mr在线性空间的大小和偏移, 返回结果为0
    // clip.start表示地址区间的起始, base为本次映射的基址, 差值就是offset
    offset_in_region = int128_get64(int128_sub(clip.start, base));
    // 最初base为0
    // 开始映射时, clip表示映射的区间范围, base作为一个移动指导每个FR的映射, remain表示clip还没映射的大小
    base = clip.start;
    // 为0xffffffffffffffffui64
    remain = clip.size;
    //Flatrange成员的初始化
    fr.mr = mr;
    fr.dirty_log_mask = memory_region_get_dirty_log_mask(mr);
    fr.romd_mode = mr->romd_mode;
    fr.readonly = readonly;
    fr.nonvolatile = nonvolatile;
    // 遍历FlatView中的FlatRanges, flatview的nr什么时候初始化？
    /* Render the region itself into any gaps left by the current view. */
    for (i = 0; i < view->nr && int128_nz(remain); ++i) {
        // 将flatrange结束地址小于mr开始地址的FlatRange排除掉
        if (int128_ge(base, addrrange_end(view->ranges[i].addr))) {
            continue;
        }
        // FlatRange开始地址大于mr开始地址
        /*如果base < = view->ranges[i].addr.start*/
        if (int128_lt(base, view->ranges[i].addr.start)) {
            /*now 表示已经存在的FR 或者本次填充的FR的长度*/
            //找出两个中小的赋值给now, min(remain, flatrange.start - base)
            now = int128_min(remain,
                             int128_sub(view->ranges[i].addr.start, base));
            // flatrange在mr中的偏移, 第一次是0
            /*fr.offset_in_region表示在整个地址空间中的偏移*/
            fr.offset_in_region = offset_in_region;
            //完成fr的addrfange的赋值, base到min(remin, start)
            fr.addr = addrrange_make(base, now);
            // 将flatrange插入flatview
            flatview_insert(view, i, &fr);
            ++i;
            // base = base + now
            int128_addto(&base, now);
            // offset_in_region = offset_in_region + now
            offset_in_region += int128_get64(now);
            // remain = remain - now
            int128_subfrom(&remain, now);
        }
        // now = min(base + remain, flatrange结束地址) - base
        now = int128_sub(int128_min(int128_add(base, remain),
                                    addrrange_end(view->ranges[i].addr)),
                         base);
        // base = base + now
        int128_addto(&base, now);
        // offset_in_region = offset_in_region + now
        offset_in_region += int128_get64(now);
        // remain = remain - now
        int128_subfrom(&remain, now);
    }
    // remain != 0
    /*如果还有剩下的clip没有映射, 则下面不会在发生冲突, 直接一次性的映射完成*/
    if (int128_nz(remain)) {
        fr.offset_in_region = offset_in_region;
        // 返回AddressRange{base, remain}
        fr.addr = addrrange_make(base, remain);
        flatview_insert(view, i, &fr);
    }
}
```

在此必须清楚MR和clip的意义, 即该函数实现的是把**MR的区域**填充**clip空间**. 填充的方式就是**生成一个个FlatRange**, 并交由FlatView管理. 基本管理逻辑理论上如图所示

![2020-02-28-23-26-43.png](./images/2020-02-28-23-26-43.png)

棕色部分意味着已经存在的映射, 这种情况下只需要把R1和R2映射进来即可. 最终FlatView中的FlatRange按照在物理地址空间的布局, 依次排列. 但是按照实际情况来讲, 实际上传递进来的MR是整个地址空间system_space,所以像图中那样比较复杂的格局应该基本不会出现. 不过咱们还是根据代码来看. 首先获取了当前MR的区间范围, 以base为起点. 我们目的是要把MR的区间映射进clip中, 所以如果两者没有交叉, 那么无法完成映射. 接着设置clip为二者地址区间重叠的部分, 以图中所示, clip就成了clip1所标的范围. 如果当前MR是某个subregion,则需要对其原始的MR进行展开, 因为具体的信息都保存在原始的MR中. 但是全局MR system_memory作为参数传递进来, 那么这里mr->alias为NULL, 所以到了下面对system_memory的每个subregion均进行展开. 就这样再次进入render_memory_region函数的时候, MR为某个subregion, clip也为subregion对应的区域和原始clip的交集, 由于其mr->alias指向原始MR, 进入if判断, 对原始MR的对应区间进行展开, 再次调用render_memory_region. 这一次就要进行真正的展开操作了, 即生成对应的FlatRange. 

顺着函数往下走, 涉及几个变量这里先介绍下, offset_in_region为对应MR在全局地址空间中的偏移, base为一个移动指针, 指向当前映射的小区间, 指导每个FR的映射. now当前已经映射的FR的长度, 有两种可能, 第一可能是当前映射的FR, 第二可能是已经映射的FR. remain表示当前clip中剩下的未映射的部分(不考虑已经存在的FR), 有了这些再看下面的代码就不吃力了. 

核心的工作起始于一个for循环, 循环的条件是 view->nr && int128_nz(remain), 表示当前还有未遍历的FR并且remain还有剩余. 循环中如果MR base的值大于或者等于当前FR的end,则继续往后遍历FR, 否则进入下面, 如果base小于当前FR的start, 则表明base到start之间的区间还没有映射, 则为其进行映射, now表示要映射的长度, 取remain和int128_sub(view->ranges[i].addr.start, base)之间的最小值, 后者表示下一个FR的start和base之间的差值, 当然按照clip为准. 接下来就没难度了, 设置FR的offset_in_region和addr,然后调用flatview_insert插入到FlatView的FlatRange数组中. 不过由于FR按照地址顺序排列, 如果插入位置靠前, 则需要移动较多的项, 不知道为何不用链表实现. 下面就很自然了移动base, 增加offset_in_region, 减少remain等操作. 出了if,此时base已经和FR的start对齐, 所以还需要略过当前FR. 就这么一直映射下去. 

出了for循环, 如果remain不为0, 则表明还有没有映射的, 但是现在已经没有已经存在的FR了, 所以不会发生冲突, 直接把remain直接映射成一个FR即可. 

按照这个思路, 吧所有的subregion都映射下去, 最终把FlatView返回. 

qemu要把**MemoryRegion**映射到cpu看到的**线性地址上**(**AddressSpace**), 但是有些情况**两个设备**的内存映射到**相同的线性地址**, 比如mmio. 举个例子,对于一个**内存条是4g**, 它的线性地址为**0-4g**, 但是**vga设备**的内存地址通过**mmio映射**到**线性地址**的`768k–(768+256k)`, 这种情况应该使vga的线性地址覆盖掉ram的`768k–(768+256k)`地址,这样写vga地址才能成功.

**FlatRang**则表示一个MemoryRegion映射到线性空间的一段地址.

qemu内存建模是通过**优先级**来实现**内存地址的覆盖**, 优先级高的MemoryRegion 先被转换为 **FlatRang**, 后面渲染的时候**低优先级**的FlatRang**不覆盖高优先级**的FlatRang, **低优先级**的**FlatRang**如果被**高优先级**的FlatRang**截断**则**只保存**不被高优先级遮盖的部分到flatview, 这是`render_memory_region` 的677行到704行的主要工作

MemoryRegion 的terminates 变量如果为false表示它是一个**纯容器**, 纯容器自身**没有线性地址**(只规定一个偏移和大小来限制子区域线性地址的取值), 通过子region来生成线性地址, 所以纯容器所规定的线性地址空间可能留下空洞,会被其他低优先级的MemoryRegion所填充MemoryRegion的addr 变量表示相对于父容器的偏移, 和大小,FlatRange的offset_in_region 变量表示该FlatRange相对所在MemoryRegion的位置(因为一个MemoryRegion可能被高优先级的MemoryRegion截断成多段,所以offset_in_region不一定为0)

fr.addr 标示该FlatRange在线性地址空间的偏移

FlatRange在FlatView中是按照地址升序来排列的, 另外不存在地址重合的FlatRange.

后面把结束地址小于MemoryRegion开始地址的FlatRange都排除掉,因为他们的地址和我们要生成的地址有冲突

剩下的地址分为如下四种情况

![2020-03-11-11-18-13.png](./images/2020-03-11-11-18-13.png)

base 表示要生成的地址空间的开始 remin表示要生成地址空间的结尾

start表示下一个要比较的地址空间的开始, end表示下一个要比较地址空间的结尾

for循环中处理的就是图中的1, 2, 4.

先把base到 min(remin, start) 这段地址生成一个FlatRange(不和其他地址重合)

将剩余部分地址裁剪出来, 其实还有一部分FlatRange可能要生成新的FlatRange(end到remin)

如果是alias还要展开自己, 这个说法是不对的. 事实上, alias mr和它指向的mr的”gpa"(base+addr)并不一定一致, 如果都展开, 映射就重复了. 

下面是info mtree 打印出来的虚拟机address-space及 memory-region(被alias mr指向的mr)

```
address-space: memory
  0000000000000000-ffffffffffffffff (prio 0, RW): system
    0000000000000000-00000000bfffffff (prio 0, RW): alias ram-below-4g @pc.ram 0000000000000000-00000000bfffffff
    0000000000000000-ffffffffffffffff (prio -1, RW): pci
      00000000000a0000-00000000000bffff (prio 1, RW): cirrus-lowmem-container
        00000000000a0000-00000000000a7fff (prio 1, RW): alias vga.bank0 @vga.vram 0000000000000000-0000000000007fff
        00000000000a0000-00000000000bffff (prio 0, RW): cirrus-low-memory
        00000000000a8000-00000000000affff (prio 1, RW): alias vga.bank1 @vga.vram 0000000000008000-000000000000ffff
      00000000000c0000-00000000000dffff (prio 1, RW): pc.rom
      00000000000e0000-00000000000fffff (prio 1, R-): alias isa-bios @pc.bios 0000000000020000-000000000003ffff
      00000000fc000000-00000000fdffffff (prio 1, RW): cirrus-pci-bar0
        00000000fc000000-00000000fc7fffff (prio 1, RW): vga.vram
        00000000fc000000-00000000fc7fffff (prio 0, RW): cirrus-linear-io
        00000000fd000000-00000000fd3fffff (prio 0, RW): cirrus-bitblt-mmio
      00000000febf0000-00000000febf0fff (prio 1, RW): cirrus-mmio
      00000000febf1000-00000000febf1fff (prio 1, RW): virtio-scsi-pci-msix
        00000000febf1000-00000000febf103f (prio 0, RW): msix-table
        00000000febf1800-00000000febf1807 (prio 0, RW): msix-pba
      00000000febf2000-00000000febf2fff (prio 1, RW): virtio-serial-pci-msix
        00000000febf2000-00000000febf201f (prio 0, RW): msix-table
        00000000febf2800-00000000febf2807 (prio 0, RW): msix-pba
      00000000fffc0000-00000000ffffffff (prio 0, R-): pc.bios
    00000000000a0000-00000000000bffff (prio 1, RW): alias smram-region @pci 00000000000a0000-00000000000bffff
    00000000000c0000-00000000000c3fff (prio 1, RW): alias pam-ram @pc.ram 00000000000c0000-00000000000c3fff [disabled]
    00000000000c0000-00000000000c3fff (prio 1, RW): alias pam-pci @pc.ram 00000000000c0000-00000000000c3fff [disabled]
    00000000000c0000-00000000000c3fff (prio 1, R-): alias pam-rom @pc.ram 00000000000c0000-00000000000c3fff
    00000000000c0000-00000000000c3fff (prio 1, RW): alias pam-pci @pci 00000000000c0000-00000000000c3fff [disabled]
    00000000000c4000-00000000000c7fff (prio 1, RW): alias pam-ram @pc.ram 00000000000c4000-00000000000c7fff [disabled]
    00000000000c4000-00000000000c7fff (prio 1, RW): alias pam-pci @pc.ram 00000000000c4000-00000000000c7fff [disabled]
    00000000000c4000-00000000000c7fff (prio 1, R-): alias pam-rom @pc.ram 00000000000c4000-00000000000c7fff
    00000000000c4000-00000000000c7fff (prio 1, RW): alias pam-pci @pci 00000000000c4000-00000000000c7fff [disabled]
    00000000000c8000-00000000000cbfff (prio 1, RW): alias pam-ram @pc.ram 00000000000c8000-00000000000cbfff [disabled]
    00000000000c8000-00000000000cbfff (prio 1, RW): alias pam-pci @pc.ram 00000000000c8000-00000000000cbfff [disabled]
    00000000000c8000-00000000000cbfff (prio 1, R-): alias pam-rom @pc.ram 00000000000c8000-00000000000cbfff
    00000000000c8000-00000000000cbfff (prio 1, RW): alias pam-pci @pci 00000000000c8000-00000000000cbfff [disabled]
    00000000000c9000-00000000000cbfff (prio 1000, RW): alias kvmvapic-rom @pc.ram 00000000000c9000-00000000000cbfff
    00000000000cc000-00000000000cffff (prio 1, RW): alias pam-ram @pc.ram 00000000000cc000-00000000000cffff [disabled]
    00000000000cc000-00000000000cffff (prio 1, RW): alias pam-pci @pc.ram 00000000000cc000-00000000000cffff [disabled]
    00000000000cc000-00000000000cffff (prio 1, R-): alias pam-rom @pc.ram 00000000000cc000-00000000000cffff
    00000000000cc000-00000000000cffff (prio 1, RW): alias pam-pci @pci 00000000000cc000-00000000000cffff [disabled]
    00000000000d0000-00000000000d3fff (prio 1, RW): alias pam-ram @pc.ram 00000000000d0000-00000000000d3fff [disabled]
    00000000000d0000-00000000000d3fff (prio 1, RW): alias pam-pci @pc.ram 00000000000d0000-00000000000d3fff [disabled]
    00000000000d0000-00000000000d3fff (prio 1, R-): alias pam-rom @pc.ram 00000000000d0000-00000000000d3fff
    00000000000d0000-00000000000d3fff (prio 1, RW): alias pam-pci @pci 00000000000d0000-00000000000d3fff [disabled]
    00000000000d4000-00000000000d7fff (prio 1, RW): alias pam-ram @pc.ram 00000000000d4000-00000000000d7fff [disabled]
    00000000000d4000-00000000000d7fff (prio 1, RW): alias pam-pci @pc.ram 00000000000d4000-00000000000d7fff [disabled]
    00000000000d4000-00000000000d7fff (prio 1, R-): alias pam-rom @pc.ram 00000000000d4000-00000000000d7fff
    00000000000d4000-00000000000d7fff (prio 1, RW): alias pam-pci @pci 00000000000d4000-00000000000d7fff [disabled]
    00000000000d8000-00000000000dbfff (prio 1, RW): alias pam-ram @pc.ram 00000000000d8000-00000000000dbfff [disabled]
    00000000000d8000-00000000000dbfff (prio 1, RW): alias pam-pci @pc.ram 00000000000d8000-00000000000dbfff [disabled]
    00000000000d8000-00000000000dbfff (prio 1, R-): alias pam-rom @pc.ram 00000000000d8000-00000000000dbfff
    00000000000d8000-00000000000dbfff (prio 1, RW): alias pam-pci @pci 00000000000d8000-00000000000dbfff [disabled]
    00000000000dc000-00000000000dffff (prio 1, RW): alias pam-ram @pc.ram 00000000000dc000-00000000000dffff [disabled]
    00000000000dc000-00000000000dffff (prio 1, RW): alias pam-pci @pc.ram 00000000000dc000-00000000000dffff [disabled]
    00000000000dc000-00000000000dffff (prio 1, R-): alias pam-rom @pc.ram 00000000000dc000-00000000000dffff
    00000000000dc000-00000000000dffff (prio 1, RW): alias pam-pci @pci 00000000000dc000-00000000000dffff [disabled]
    00000000000e0000-00000000000e3fff (prio 1, RW): alias pam-ram @pc.ram 00000000000e0000-00000000000e3fff [disabled]
    00000000000e0000-00000000000e3fff (prio 1, RW): alias pam-pci @pc.ram 00000000000e0000-00000000000e3fff [disabled]
    00000000000e0000-00000000000e3fff (prio 1, R-): alias pam-rom @pc.ram 00000000000e0000-00000000000e3fff
    00000000000e0000-00000000000e3fff (prio 1, RW): alias pam-pci @pci 00000000000e0000-00000000000e3fff [disabled]
    00000000000e4000-00000000000e7fff (prio 1, RW): alias pam-ram @pc.ram 00000000000e4000-00000000000e7fff [disabled]
    00000000000e4000-00000000000e7fff (prio 1, RW): alias pam-pci @pc.ram 00000000000e4000-00000000000e7fff [disabled]
    00000000000e4000-00000000000e7fff (prio 1, R-): alias pam-rom @pc.ram 00000000000e4000-00000000000e7fff
    00000000000e4000-00000000000e7fff (prio 1, RW): alias pam-pci @pci 00000000000e4000-00000000000e7fff [disabled]
    00000000000e8000-00000000000ebfff (prio 1, RW): alias pam-ram @pc.ram 00000000000e8000-00000000000ebfff [disabled]
    00000000000e8000-00000000000ebfff (prio 1, RW): alias pam-pci @pc.ram 00000000000e8000-00000000000ebfff [disabled]
    00000000000e8000-00000000000ebfff (prio 1, R-): alias pam-rom @pc.ram 00000000000e8000-00000000000ebfff
    00000000000e8000-00000000000ebfff (prio 1, RW): alias pam-pci @pci 00000000000e8000-00000000000ebfff [disabled]
    00000000000ec000-00000000000effff (prio 1, RW): alias pam-ram @pc.ram 00000000000ec000-00000000000effff
    00000000000ec000-00000000000effff (prio 1, RW): alias pam-pci @pc.ram 00000000000ec000-00000000000effff [disabled]
    00000000000ec000-00000000000effff (prio 1, R-): alias pam-rom @pc.ram 00000000000ec000-00000000000effff [disabled]
    00000000000ec000-00000000000effff (prio 1, RW): alias pam-pci @pci 00000000000ec000-00000000000effff [disabled]
    00000000000f0000-00000000000fffff (prio 1, RW): alias pam-ram @pc.ram 00000000000f0000-00000000000fffff [disabled]
    00000000000f0000-00000000000fffff (prio 1, RW): alias pam-pci @pc.ram 00000000000f0000-00000000000fffff [disabled]
    00000000000f0000-00000000000fffff (prio 1, R-): alias pam-rom @pc.ram 00000000000f0000-00000000000fffff
    00000000000f0000-00000000000fffff (prio 1, RW): alias pam-pci @pci 00000000000f0000-00000000000fffff [disabled]
    00000000fec00000-00000000fec00fff (prio 0, RW): kvm-ioapic
    00000000fee00000-00000000feefffff (prio 4096, RW): kvm-apic-msi
    0000000100000000-000000013fffffff (prio 0, RW): alias ram-above-4g @pc.ram 00000000c0000000-00000000ffffffff

address-space: I/O
  0000000000000000-000000000000ffff (prio 0, RW): io
    0000000000000000-0000000000000007 (prio 0, RW): dma-chan
    0000000000000008-000000000000000f (prio 0, RW): dma-cont
    0000000000000020-0000000000000021 (prio 0, RW): kvm-pic
    0000000000000040-0000000000000043 (prio 0, RW): kvm-pit
    0000000000000060-0000000000000060 (prio 0, RW): i8042-data
    0000000000000061-0000000000000061 (prio 0, RW): pcspk
    0000000000000064-0000000000000064 (prio 0, RW): i8042-cmd
    0000000000000070-0000000000000071 (prio 0, RW): rtc
    000000000000007e-000000000000007f (prio 0, RW): kvmvapic
    0000000000000080-0000000000000080 (prio 0, RW): ioport80
    0000000000000081-0000000000000083 (prio 0, RW): dma-page
    0000000000000087-0000000000000087 (prio 0, RW): dma-page
    0000000000000089-000000000000008b (prio 0, RW): dma-page
    000000000000008f-000000000000008f (prio 0, RW): dma-page
    0000000000000092-0000000000000092 (prio 0, RW): port92
    00000000000000a0-00000000000000a1 (prio 0, RW): kvm-pic
    00000000000000b2-00000000000000b3 (prio 0, RW): apm-io
    00000000000000c0-00000000000000cf (prio 0, RW): dma-chan
    00000000000000d0-00000000000000df (prio 0, RW): dma-cont
    00000000000000f0-00000000000000f0 (prio 0, RW): ioportF0
    0000000000000170-0000000000000177 (prio 0, RW): ide
    00000000000001f0-00000000000001f7 (prio 0, RW): ide
    0000000000000376-0000000000000376 (prio 0, RW): ide
    00000000000003b0-00000000000003df (prio 0, RW): cirrus-io
    00000000000003f1-00000000000003f5 (prio 0, RW): fdc
    00000000000003f6-00000000000003f6 (prio 0, RW): ide
    00000000000003f7-00000000000003f7 (prio 0, RW): fdc
    00000000000003f8-00000000000003ff (prio 0, RW): serial
    00000000000004d0-00000000000004d0 (prio 0, RW): kvm-elcr
    00000000000004d1-00000000000004d1 (prio 0, RW): kvm-elcr
    0000000000000510-0000000000000511 (prio 0, RW): fwcfg
    0000000000000514-000000000000051b (prio 0, RW): fwcfg.dma
    0000000000000600-000000000000063f (prio 0, RW): piix4-pm
      0000000000000600-0000000000000603 (prio 0, RW): acpi-evt
      0000000000000604-0000000000000605 (prio 0, RW): acpi-cnt
      0000000000000608-000000000000060b (prio 0, RW): acpi-tmr
    0000000000000700-000000000000073f (prio 0, RW): pm-smbus
    0000000000000cf8-0000000000000cfb (prio 0, RW): pci-conf-idx
    0000000000000cf9-0000000000000cf9 (prio 1, RW): piix3-reset-control
    0000000000000cfc-0000000000000cff (prio 0, RW): pci-conf-data
    0000000000005658-0000000000005658 (prio 0, RW): vmport
    000000000000ae00-000000000000ae13 (prio 0, RW): acpi-pci-hotplug
    000000000000af00-000000000000af1f (prio 0, RW): acpi-cpu-hotplug
    000000000000afe0-000000000000afe3 (prio 0, RW): acpi-gpe0
    000000000000c000-000000000000c0ff (prio 1, RW): pv_channel
    000000000000c100-000000000000c13f (prio 1, RW): virtio-pci
    000000000000c140-000000000000c15f (prio 1, RW): uhci
    000000000000c160-000000000000c17f (prio 1, RW): virtio-pci
    000000000000c180-000000000000c19f (prio 1, RW): virtio-pci
    000000000000c1a0-000000000000c1af (prio 1, RW): piix-bmdma-container
      000000000000c1a0-000000000000c1a3 (prio 0, RW): piix-bmdma
      000000000000c1a4-000000000000c1a7 (prio 0, RW): bmdma
      000000000000c1a8-000000000000c1ab (prio 0, RW): piix-bmdma
      000000000000c1ac-000000000000c1af (prio 0, RW): bmdma

address-space: i440FX
  0000000000000000-ffffffffffffffff (prio 0, RW): alias bus master @system 0000000000000000-ffffffffffffffff [disabled]

address-space: PIIX3
  0000000000000000-ffffffffffffffff (prio 0, RW): alias bus master @system 0000000000000000-ffffffffffffffff [disabled]

address-space: piix3-ide
  0000000000000000-ffffffffffffffff (prio 0, RW): alias bus master @system 0000000000000000-ffffffffffffffff

address-space: PIIX4_PM
  0000000000000000-ffffffffffffffff (prio 0, RW): alias bus master @system 0000000000000000-ffffffffffffffff [disabled]

address-space: piix3-usb-uhci
  0000000000000000-ffffffffffffffff (prio 0, RW): alias bus master @system 0000000000000000-ffffffffffffffff

address-space: virtio-scsi-pci
  0000000000000000-ffffffffffffffff (prio 0, RW): alias bus master @system 0000000000000000-ffffffffffffffff

address-space: virtio-pci-cfg-as
  0000000000000000-00000000007fffff (prio 0, RW): alias virtio-pci-cfg @virtio-pci 0000000000000000-00000000007fffff

address-space: virtio-serial-pci
  0000000000000000-ffffffffffffffff (prio 0, RW): alias bus master @system 0000000000000000-ffffffffffffffff

address-space: virtio-pci-cfg-as
  0000000000000000-00000000007fffff (prio 0, RW): alias virtio-pci-cfg @virtio-pci 0000000000000000-00000000007fffff

address-space: cirrus-vga
  0000000000000000-ffffffffffffffff (prio 0, RW): alias bus master @system 0000000000000000-ffffffffffffffff [disabled]

address-space: virtio-balloon-pci
  0000000000000000-ffffffffffffffff (prio 0, RW): alias bus master @system 0000000000000000-ffffffffffffffff

address-space: virtio-pci-cfg-as
  0000000000000000-00000000007fffff (prio 0, RW): alias virtio-pci-cfg @virtio-pci 0000000000000000-00000000007fffff

address-space: pv_channel
  0000000000000000-ffffffffffffffff (prio 0, RW): alias bus master @system 0000000000000000-ffffffffffffffff [disabled]

address-space: KVM-SMRAM
  0000000000000000-ffffffffffffffff (prio 0, RW): mem-container-smram
    0000000000000000-00000000ffffffff (prio 10, RW): smram
      00000000000a0000-00000000000bffff (prio 0, RW): alias smram-low @pc.ram 00000000000a0000-00000000000bffff
    0000000000000000-ffffffffffffffff (prio 0, RW): alias mem-smram @system 0000000000000000-ffffffffffffffff

memory-region: pc.ram
  0000000000000000-00000000ffffffff (prio 0, RW): pc.ram

memory-region: vga.vram
  0000000000000000-00000000007fffff (prio 1, RW): vga.vram

memory-region: pc.bios
  00000000fffc0000-00000000ffffffff (prio 0, R-): pc.bios

memory-region: pci
  0000000000000000-ffffffffffffffff (prio -1, RW): pci
    00000000000a0000-00000000000bffff (prio 1, RW): cirrus-lowmem-container
      00000000000a0000-00000000000a7fff (prio 1, RW): alias vga.bank0 @vga.vram 0000000000000000-0000000000007fff
      00000000000a0000-00000000000bffff (prio 0, RW): cirrus-low-memory
      00000000000a8000-00000000000affff (prio 1, RW): alias vga.bank1 @vga.vram 0000000000008000-000000000000ffff
    00000000000c0000-00000000000dffff (prio 1, RW): pc.rom
    00000000000e0000-00000000000fffff (prio 1, R-): alias isa-bios @pc.bios 0000000000020000-000000000003ffff
    00000000fc000000-00000000fdffffff (prio 1, RW): cirrus-pci-bar0
      00000000fc000000-00000000fc7fffff (prio 1, RW): vga.vram
      00000000fc000000-00000000fc7fffff (prio 0, RW): cirrus-linear-io
      00000000fd000000-00000000fd3fffff (prio 0, RW): cirrus-bitblt-mmio
    00000000febf0000-00000000febf0fff (prio 1, RW): cirrus-mmio
    00000000febf1000-00000000febf1fff (prio 1, RW): virtio-scsi-pci-msix
      00000000febf1000-00000000febf103f (prio 0, RW): msix-table
      00000000febf1800-00000000febf1807 (prio 0, RW): msix-pba
    00000000febf2000-00000000febf2fff (prio 1, RW): virtio-serial-pci-msix
      00000000febf2000-00000000febf201f (prio 0, RW): msix-table
      00000000febf2800-00000000febf2807 (prio 0, RW): msix-pba
    00000000fffc0000-00000000ffffffff (prio 0, R-): pc.bios

memory-region: system
  0000000000000000-ffffffffffffffff (prio 0, RW): system
    0000000000000000-00000000bfffffff (prio 0, RW): alias ram-below-4g @pc.ram 0000000000000000-00000000bfffffff
    0000000000000000-ffffffffffffffff (prio -1, RW): pci
      00000000000a0000-00000000000bffff (prio 1, RW): cirrus-lowmem-container
        00000000000a0000-00000000000a7fff (prio 1, RW): alias vga.bank0 @vga.vram 0000000000000000-0000000000007fff
        00000000000a0000-00000000000bffff (prio 0, RW): cirrus-low-memory
        00000000000a8000-00000000000affff (prio 1, RW): alias vga.bank1 @vga.vram 0000000000008000-000000000000ffff
      00000000000c0000-00000000000dffff (prio 1, RW): pc.rom
      00000000000e0000-00000000000fffff (prio 1, R-): alias isa-bios @pc.bios 0000000000020000-000000000003ffff
      00000000fc000000-00000000fdffffff (prio 1, RW): cirrus-pci-bar0
        00000000fc000000-00000000fc7fffff (prio 1, RW): vga.vram
        00000000fc000000-00000000fc7fffff (prio 0, RW): cirrus-linear-io
        00000000fd000000-00000000fd3fffff (prio 0, RW): cirrus-bitblt-mmio
      00000000febf0000-00000000febf0fff (prio 1, RW): cirrus-mmio
      00000000febf1000-00000000febf1fff (prio 1, RW): virtio-scsi-pci-msix
        00000000febf1000-00000000febf103f (prio 0, RW): msix-table
        00000000febf1800-00000000febf1807 (prio 0, RW): msix-pba
      00000000febf2000-00000000febf2fff (prio 1, RW): virtio-serial-pci-msix
        00000000febf2000-00000000febf201f (prio 0, RW): msix-table
        00000000febf2800-00000000febf2807 (prio 0, RW): msix-pba
      00000000fffc0000-00000000ffffffff (prio 0, R-): pc.bios
    00000000000a0000-00000000000bffff (prio 1, RW): alias smram-region @pci 00000000000a0000-00000000000bffff
    00000000000c0000-00000000000c3fff (prio 1, RW): alias pam-ram @pc.ram 00000000000c0000-00000000000c3fff [disabled]
    00000000000c0000-00000000000c3fff (prio 1, RW): alias pam-pci @pc.ram 00000000000c0000-00000000000c3fff [disabled]
    00000000000c0000-00000000000c3fff (prio 1, R-): alias pam-rom @pc.ram 00000000000c0000-00000000000c3fff
    00000000000c0000-00000000000c3fff (prio 1, RW): alias pam-pci @pci 00000000000c0000-00000000000c3fff [disabled]
    00000000000c4000-00000000000c7fff (prio 1, RW): alias pam-ram @pc.ram 00000000000c4000-00000000000c7fff [disabled]
    00000000000c4000-00000000000c7fff (prio 1, RW): alias pam-pci @pc.ram 00000000000c4000-00000000000c7fff [disabled]
    00000000000c4000-00000000000c7fff (prio 1, R-): alias pam-rom @pc.ram 00000000000c4000-00000000000c7fff
    00000000000c4000-00000000000c7fff (prio 1, RW): alias pam-pci @pci 00000000000c4000-00000000000c7fff [disabled]
    00000000000c8000-00000000000cbfff (prio 1, RW): alias pam-ram @pc.ram 00000000000c8000-00000000000cbfff [disabled]
    00000000000c8000-00000000000cbfff (prio 1, RW): alias pam-pci @pc.ram 00000000000c8000-00000000000cbfff [disabled]
    00000000000c8000-00000000000cbfff (prio 1, R-): alias pam-rom @pc.ram 00000000000c8000-00000000000cbfff
    00000000000c8000-00000000000cbfff (prio 1, RW): alias pam-pci @pci 00000000000c8000-00000000000cbfff [disabled]
    00000000000c9000-00000000000cbfff (prio 1000, RW): alias kvmvapic-rom @pc.ram 00000000000c9000-00000000000cbfff
    00000000000cc000-00000000000cffff (prio 1, RW): alias pam-ram @pc.ram 00000000000cc000-00000000000cffff [disabled]
    00000000000cc000-00000000000cffff (prio 1, RW): alias pam-pci @pc.ram 00000000000cc000-00000000000cffff [disabled]
    00000000000cc000-00000000000cffff (prio 1, R-): alias pam-rom @pc.ram 00000000000cc000-00000000000cffff
    00000000000cc000-00000000000cffff (prio 1, RW): alias pam-pci @pci 00000000000cc000-00000000000cffff [disabled]
    00000000000d0000-00000000000d3fff (prio 1, RW): alias pam-ram @pc.ram 00000000000d0000-00000000000d3fff [disabled]
    00000000000d0000-00000000000d3fff (prio 1, RW): alias pam-pci @pc.ram 00000000000d0000-00000000000d3fff [disabled]
    00000000000d0000-00000000000d3fff (prio 1, R-): alias pam-rom @pc.ram 00000000000d0000-00000000000d3fff
    00000000000d0000-00000000000d3fff (prio 1, RW): alias pam-pci @pci 00000000000d0000-00000000000d3fff [disabled]
    00000000000d4000-00000000000d7fff (prio 1, RW): alias pam-ram @pc.ram 00000000000d4000-00000000000d7fff [disabled]
    00000000000d4000-00000000000d7fff (prio 1, RW): alias pam-pci @pc.ram 00000000000d4000-00000000000d7fff [disabled]
    00000000000d4000-00000000000d7fff (prio 1, R-): alias pam-rom @pc.ram 00000000000d4000-00000000000d7fff
    00000000000d4000-00000000000d7fff (prio 1, RW): alias pam-pci @pci 00000000000d4000-00000000000d7fff [disabled]
    00000000000d8000-00000000000dbfff (prio 1, RW): alias pam-ram @pc.ram 00000000000d8000-00000000000dbfff [disabled]
    00000000000d8000-00000000000dbfff (prio 1, RW): alias pam-pci @pc.ram 00000000000d8000-00000000000dbfff [disabled]
    00000000000d8000-00000000000dbfff (prio 1, R-): alias pam-rom @pc.ram 00000000000d8000-00000000000dbfff
    00000000000d8000-00000000000dbfff (prio 1, RW): alias pam-pci @pci 00000000000d8000-00000000000dbfff [disabled]
    00000000000dc000-00000000000dffff (prio 1, RW): alias pam-ram @pc.ram 00000000000dc000-00000000000dffff [disabled]
    00000000000dc000-00000000000dffff (prio 1, RW): alias pam-pci @pc.ram 00000000000dc000-00000000000dffff [disabled]
    00000000000dc000-00000000000dffff (prio 1, R-): alias pam-rom @pc.ram 00000000000dc000-00000000000dffff
    00000000000dc000-00000000000dffff (prio 1, RW): alias pam-pci @pci 00000000000dc000-00000000000dffff [disabled]
    00000000000e0000-00000000000e3fff (prio 1, RW): alias pam-ram @pc.ram 00000000000e0000-00000000000e3fff [disabled]
    00000000000e0000-00000000000e3fff (prio 1, RW): alias pam-pci @pc.ram 00000000000e0000-00000000000e3fff [disabled]
    00000000000e0000-00000000000e3fff (prio 1, R-): alias pam-rom @pc.ram 00000000000e0000-00000000000e3fff
    00000000000e0000-00000000000e3fff (prio 1, RW): alias pam-pci @pci 00000000000e0000-00000000000e3fff [disabled]
    00000000000e4000-00000000000e7fff (prio 1, RW): alias pam-ram @pc.ram 00000000000e4000-00000000000e7fff [disabled]
    00000000000e4000-00000000000e7fff (prio 1, RW): alias pam-pci @pc.ram 00000000000e4000-00000000000e7fff [disabled]
    00000000000e4000-00000000000e7fff (prio 1, R-): alias pam-rom @pc.ram 00000000000e4000-00000000000e7fff
    00000000000e4000-00000000000e7fff (prio 1, RW): alias pam-pci @pci 00000000000e4000-00000000000e7fff [disabled]
    00000000000e8000-00000000000ebfff (prio 1, RW): alias pam-ram @pc.ram 00000000000e8000-00000000000ebfff [disabled]
    00000000000e8000-00000000000ebfff (prio 1, RW): alias pam-pci @pc.ram 00000000000e8000-00000000000ebfff [disabled]
    00000000000e8000-00000000000ebfff (prio 1, R-): alias pam-rom @pc.ram 00000000000e8000-00000000000ebfff
    00000000000e8000-00000000000ebfff (prio 1, RW): alias pam-pci @pci 00000000000e8000-00000000000ebfff [disabled]
    00000000000ec000-00000000000effff (prio 1, RW): alias pam-ram @pc.ram 00000000000ec000-00000000000effff
    00000000000ec000-00000000000effff (prio 1, RW): alias pam-pci @pc.ram 00000000000ec000-00000000000effff [disabled]
    00000000000ec000-00000000000effff (prio 1, R-): alias pam-rom @pc.ram 00000000000ec000-00000000000effff [disabled]
    00000000000ec000-00000000000effff (prio 1, RW): alias pam-pci @pci 00000000000ec000-00000000000effff [disabled]
    00000000000f0000-00000000000fffff (prio 1, RW): alias pam-ram @pc.ram 00000000000f0000-00000000000fffff [disabled]
    00000000000f0000-00000000000fffff (prio 1, RW): alias pam-pci @pc.ram 00000000000f0000-00000000000fffff [disabled]
    00000000000f0000-00000000000fffff (prio 1, R-): alias pam-rom @pc.ram 00000000000f0000-00000000000fffff
    00000000000f0000-00000000000fffff (prio 1, RW): alias pam-pci @pci 00000000000f0000-00000000000fffff [disabled]
    00000000fec00000-00000000fec00fff (prio 0, RW): kvm-ioapic
    00000000fee00000-00000000feefffff (prio 4096, RW): kvm-apic-msi
    0000000100000000-000000013fffffff (prio 0, RW): alias ram-above-4g @pc.ram 00000000c0000000-00000000ffffffff

memory-region: virtio-pci
  0000000000000000-00000000007fffff (prio 0, RW): virtio-pci

memory-region: virtio-pci
  0000000000000000-00000000007fffff (prio 0, RW): virtio-pci

memory-region: virtio-pci
  0000000000000000-00000000007fffff (prio 0, RW): virtio-pci
```

#### 4.3.1.2. address_space_set_flatview(): 设置as的FlatView, 会调用KVM

```cpp
static void address_space_set_flatview(AddressSpace *as)
{
    // 返回as的current_map
    FlatView *old_view = address_space_to_flatview(as);
    // 获取AddressSpace的root MR
    MemoryRegion *physmr = memory_region_get_flatview_root(as->root);
    // 在哈希表flat_views中根据physmr(key)查找新的new_view
    FlatView *new_view = g_hash_table_lookup(flat_views, physmr);

    assert(new_view);
    // 新旧相等, 不用更新
    if (old_view == new_view) {
        return;
    }
    // 下面逻辑是新旧flatview不等

    // 旧的非空则引用计数 + 1
    if (old_view) {
        flatview_ref(old_view);
    }

    // 新的增加引用
    flatview_ref(new_view);

    if (!QTAILQ_EMPTY(&as->listeners)) {
        FlatView tmpview = { .nr = 0 }, *old_view2 = old_view;
        // 旧的fv是空的, 则旧fv使用一个fr数目为0的fv
        // 要不然就用旧的fv
        if (!old_view2) {
            old_view2 = &tmpview;
        }
        // 删除
        address_space_update_topology_pass(as, old_view2, new_view, false);
        // 新加, 传参
        address_space_update_topology_pass(as, old_view2, new_view, true);
    }

    /* Writes are protected by the BQL.  */
    /* 设置新的FlatView */
    atomic_rcu_set(&as->current_map, new_view);
    // 旧的引用计数 - 1
    if (old_view) {
        flatview_unref(old_view);
    }

    /* Note that all the old MemoryRegions are still alive up to this
     * point.  This relieves most MemoryListeners from the need to
     * ref/unref the MemoryRegions they get---unless they use them
     * outside the iothread mutex, in which case precise reference
     * counting is necessary.
     */
    if (old_view) {
        flatview_unref(old_view);
    }
}
```

在获取了**新旧两个FlatView**之后, 调用了**两次**`address_space_update_topology_pass()`函数, 首次调用重在**删除原来的**, 而后者重在**添加**. 

之后设置`as->current_map = new_view`. 

对`old_view`**减少引用**, 当**引用计数为1**时会**被删除**. 

接下来重点在两个地方: 

1、如何根据一个MR获取对应的FlatView; 

2、如何对旧的FlatView进行更新. 

```cpp
static void address_space_update_topology_pass(AddressSpace *as,
                                               const FlatView *old_view,
                                               const FlatView *new_view,
                                               bool adding)
{
    unsigned iold, inew;
    FlatRange *frold, *frnew;

    /* Generate a symmetric difference of the old and new memory maps.
     * Kill ranges in the old map, and instantiate ranges in the new map.
     */
    iold = inew = 0;
    // 循环条件是old_view->nr和new_view->nr, 即新旧view的可用fr数目
    while (iold < old_view->nr || inew < new_view->nr) {
        if (iold < old_view->nr) {
            frold = &old_view->ranges[iold];
        } else {
            frold = NULL;
        }
        if (inew < new_view->nr) {
            // flatrange数组
            frnew = &new_view->ranges[inew];
        } else {
            frnew = NULL;
        }

        if (frold
            && (!frnew
                || int128_lt(frold->addr.start, frnew->addr.start)
                || (int128_eq(frold->addr.start, frnew->addr.start)
                    && !flatrange_equal(frold, frnew)))) {
            /* In old but not in new, or in both but attributes changed. */

            if (!adding) {
                flat_range_coalesced_io_del(frold, as);
                MEMORY_LISTENER_UPDATE_REGION(frold, as, Reverse, region_del);
            }

            ++iold;
        } else if (frold && frnew && flatrange_equal(frold, frnew)) {
            /* In both and unchanged (except logging may have changed) */

            if (adding) {
                MEMORY_LISTENER_UPDATE_REGION(frnew, as, Forward, region_nop);
                if (frnew->dirty_log_mask & ~frold->dirty_log_mask) {
                    MEMORY_LISTENER_UPDATE_REGION(frnew, as, Forward, log_start,
                                                  frold->dirty_log_mask,
                                                  frnew->dirty_log_mask);
                }
                if (frold->dirty_log_mask & ~frnew->dirty_log_mask) {
                    MEMORY_LISTENER_UPDATE_REGION(frnew, as, Reverse, log_stop,
                                                  frold->dirty_log_mask,
                                                  frnew->dirty_log_mask);
                }
            }

            ++iold;
            ++inew;
        } else {
            /* In new */

            if (adding) {
                MEMORY_LISTENER_UPDATE_REGION(frnew, as, Forward, region_add);
                flat_range_coalesced_io_add(frnew, as);
            }

            ++inew;
        }
    }
}
```

该函数倒是不长, 主体是一个**while循环**, 循环条件是`old_view->nr`和`new_view->nr`,表示**新旧view**的**可用FlatRange数目**. 

这里依次对**FR数组**的**对应FR** 做对比, 主要由下面几种情况: **frold**和**frnew**均存在、frold存在但frnew不存在, frold不存在但frnew存在. 

下面的if划分和上面的略有不同: 

1、如果`frold不为空&&(frnew为空||frold.start<frnew.start||frold.start=frnew.start)&&frold!=frnew`: 这种情况是**新旧view的地址范围不一样**, 则需要调用lienter的`region_del`对**frold进行删除！！！**. 

2、如果**frold和frnew均不为空**且`frold.start=frnew.start`: 这种情况需要判断**日志掩码**, 如果`frold->dirty_log_mask && !frnew->dirty_log_mask`, 调用`log_stop`回调函数; 如果`frnew->dirty_log_mask && !frold->dirty_log_mask`, 调用`log_start`回调函数. 

3、**frold为空**但是**frnew不为空**: 这种情况直接调用`region_add`回调函数**添加region**. 

函数主体逻辑基本如上所述, 那我们注意到, 当**adding为false**时, 执行的**只有第一个情况**下的处理, 就是删除frold的操作, 其余的处理只有在**adding 为true**的时候才得以执行. 这意图就比较明确, **首次执行先删除多余的**, 下次**直接添加**或者**对日志做更新操作**了. 

会调用`MEMORY_LISTENER_UPDATE_REGION()`**提交本次修改**

# 5. MEMORY_LISTENER_UPDATE_REGION(): 新FlatRange的更新

对于要添加的FR, 调用了 `MEMORY_LISTENER_UPDATE_REGION(x)`

```cpp
/* No need to ref/unref .mr, the FlatRange keeps it alive.  */
#define MEMORY_LISTENER_UPDATE_REGION(fr, as, dir, callback, _args...)  \
    do {                                                                \
        MemoryRegionSection mrs = section_from_flat_range(fr,           \
                address_space_to_flatview(as));                         \
        MEMORY_LISTENER_CALL(as, callback, dir, &mrs, ##_args);         \
    } while(0)

// 将flatview转换成MemoryRegionSection
static inline MemoryRegionSection
section_from_flat_range(FlatRange *fr, FlatView *fv)
{
    return (MemoryRegionSection) {
        // fr对应的mr
        .mr = fr->mr,
        .fv = fv,
        .offset_within_region = fr->offset_in_region, // 在mr中的offset
        .size = fr->addr.size, // fr在as中所占大小
        .offset_within_address_space = int128_get64(fr->addr.start), // 在虚拟机物理地址空间的起始地址, GPA
        .readonly = fr->readonly, // 是否可写
        .nonvolatile = fr->nonvolatile,
    };
}
```

其中`address_space_to_flatview`会返回as的`current_map`, 这个值应该是旧的flatview

该宏实际上是另一个宏`MEMORY_LISTENER_CALL`的封装, 在`MEMORY_LISTENER_CALL`中临时生成一个`MemoryRegionSection`结构, 具体逻辑如下

```cpp
#define MEMORY_LISTENER_CALL(_as, _callback, _direction, _section, _args...) \
    do {                                                                \
        MemoryListener *_listener;                                      \
                                                                        \
        switch (_direction) {                                           \
        case Forward:                                                   \
            QTAILQ_FOREACH(_listener, &(_as)->listeners, link_as) {     \
                if (_listener->_callback) {                             \
                    _listener->_callback(_listener, _section, ##_args); \
                }                                                       \
            }                                                           \
            break;                                                      \
        case Reverse:                                                   \
            QTAILQ_FOREACH_REVERSE(_listener, &(_as)->listeners, link_as) { \
                if (_listener->_callback) {                             \
                    _listener->_callback(_listener, _section, ##_args); \
                }                                                       \
            }                                                           \
            break;                                                      \
        default:                                                        \
            abort();                                                    \
        }                                                               \
    } while (0)
```

这里有个`_direction`, 其实就是**遍历方向**, 因为**listener**按照**优先级**从**低到高**排列, 所以这里其实就是**确定让谁先处理**. 

**Forward**就是**从前向后**, 而**reverse**就是**从后向前**. 

还有一个值得注意的是`memory_listener_match`函数, **listener**有着**对应的AddressSpace**, 会在其 `address_space_filter` 域指定, 注意如果**没有指定AddressSpace**, 那么该listener对**所有AddressSpace均适用**, 否则**只适用于其指定的AddressSpace**. 知道这些, 看这些代码就不成问题了. 

这样`kvm_region_add()`函数得到执行. 

```cpp
static void kvm_region_add(MemoryListener *listener,
                           MemoryRegionSection *section)
{
    KVMMemoryListener *kml = container_of(listener, KVMMemoryListener, listener);
    // mr引用加1
    memory_region_ref(section->mr);
    kvm_set_phys_mem(kml, section, true);
}

static void kvm_region_del(MemoryListener *listener,
                           MemoryRegionSection *section)
{
    KVMMemoryListener *kml = container_of(listener, KVMMemoryListener, listener);

    kvm_set_phys_mem(kml, section, false);
    // mr引用减1
    memory_region_unref(section->mr);
}
```

`kvm_region_add()`函数是核心listener的添加region的函数, 在qemu申请好内存后, 针对**每个FR**, 调用了listener的`region_add函数`. 最终需要利用此函数把**region信息**告知**KVM**, KVM以此对内存信息做记录. 

## 5.1. kvm_set_phys_mem(): 修改内核内存

咱们直奔主题, 函数核心在`static void kvm_set_phys_mem(MemoryRegionSection *section, bool add)`函数中, QEMU通过该函数修改虚拟机注册在内核中的内存, 达到为虚拟机添加/删除/移动内存的目的.

```cpp
static void kvm_set_phys_mem(KVMMemoryListener *kml,
                             MemoryRegionSection *section, bool add)
{
    KVMSlot *mem;
    int err;
    MemoryRegion *mr = section->mr;
    // 是否可写
    bool writeable = !mr->readonly && !mr->rom_device;
    hwaddr start_addr, size, slot_size;
    void *ram;
    // 如果不是ram, 则不能写操作
    if (!memory_region_is_ram(mr)) {
        // 可写 或 kvm不支持只读内存, 直接返回
        if (writeable || !kvm_readonly_mem_allowed) {
            return;
        } else if (!mr->romd_mode) {
            /* If the memory device is not in romd_mode, then we actually want
             * to remove the kvm memory slot so all accesses will trap. */
            add = false;
        }
    }
    // 得到section的start address和size, 对齐后的结果
    // start_addr是该段内存<fr/section>在虚拟机地址空间的的起始地址, GPA, 虚拟机物理地址
    size = kvm_align_section(section, &start_addr);
    if (!size) {
        return;
    }
    // 该section/fr所属的mr在分配的主机虚拟地址中的偏移(HVA) + 该块(section/fr)在所属mr中的偏移 + 
    // 该块<fr/section>在虚拟机地址空间的起始地址(GPA)的对齐结果 - 该块<fr/section>在虚拟机地址空间的起始地址(GPA) 
    // 后面这个是对齐的偏差
    /* use aligned delta to align the ram address */
    ram = memory_region_get_ram_ptr(mr) + section->offset_within_region +
          (start_addr - section->offset_within_address_space);
    // 加锁
    kvm_slots_lock(kml);
    // 删除
    if (!add) {
        // 循环
        do {
            slot_size = MIN(kvm_max_slot_size, size);
            /*  */ 
            mem = kvm_lookup_matching_slot(kml, start_addr, slot_size);
            if (!mem) {
                goto out;
            }
            if (mem->flags & KVM_MEM_LOG_DIRTY_PAGES) {
                kvm_physical_sync_dirty_bitmap(kml, section);
            }

            /* unregister the slot */
            g_free(mem->dirty_bmap);
            mem->dirty_bmap = NULL;
            mem->memory_size = 0;
            mem->flags = 0;
            err = kvm_set_user_memory_region(kml, mem, false);
            if (err) {
                fprintf(stderr, "%s: error unregistering slot: %s\n",
                        __func__, strerror(-err));
                abort();
            }
            start_addr += slot_size;
            size -= slot_size;
        } while (size);
        goto out;
    }
    // 注册新的slot
    /* register the new slot */
    do {
        slot_size = MIN(kvm_max_slot_size, size);
        // 生成新的slot并初始化
        mem = kvm_alloc_slot(kml);
        // 内存大小
        mem->memory_size = slot_size;
        // start_addr是该段内存的起始地址, GPA, 虚拟机物理地址
        mem->start_addr = start_addr;
        // 主机虚拟地址, HVA, qemu分配的
        mem->ram = ram;
        mem->flags = kvm_mem_flags(mr);

        if (mem->flags & KVM_MEM_LOG_DIRTY_PAGES) {
            /*
             * Reallocate the bmap; it means it doesn't disappear in
             * middle of a migrate.
             */
            kvm_memslot_init_dirty_bitmap(mem);
        }
        err = kvm_set_user_memory_region(kml, mem, true);
        if (err) {
            fprintf(stderr, "%s: error registering slot: %s\n", __func__,
                    strerror(-err));
            abort();
        }
        start_addr += slot_size;
        ram += slot_size;
        size -= slot_size;
    } while (size);

out:
    kvm_slots_unlock(kml);
}
```

### 5.1.1. 属性检查

获取**section对应的MR**的一些属性, 如writeable、readonly_flag. 

如果对应的MR关联的内存并**不是作为ram存在**, 就要进行额外的验证. 这种情况如果**writeable**允许写操作或者**kvm不支持只读内存**, 那么**直接返回**. 

### 5.1.2. kvm_align_section(): 得到section/fr的起始地址和大小

然后获取section的`start_addr`和size, 其中`start_addr`就是section中的`offset_within_address_space`也就是**FR**中的`offset_in_region`,接下来对size进行了对齐操作. 

```cpp
/*
 * Calculate and align the start address and the size of the section.
 * Return the size. If the size is 0, the aligned section is empty.
 */
static hwaddr kvm_align_section(MemoryRegionSection *section,
                                hwaddr *start)
{
    // 内存大小
    hwaddr size = int128_get64(section->size);
    hwaddr delta, aligned;

    /* kvm works in page size chunks, but the function may be called
       with sub-page size and unaligned start address. Pad the start
       address to next and truncate size to previous page boundary. */
    // 将在地址空间的偏移位置对齐到qemu_real_host_page_size, 
    // ROUND_UP(9,2)=10, 本来位置9改成对齐到位置10
    aligned = ROUND_UP(section->offset_within_address_space,
                       qemu_real_host_page_size);
    // 减去原大小, 得到偏移
    delta = aligned - section->offset_within_address_space;
    // start等于地址空间起始地址的对齐结果
    *start = aligned;
    if (delta > size) {
        return 0;
    }
    // 返回size
    return (size - delta) & qemu_real_host_page_mask;
}
```

### 5.1.3. 计算该section/fr对应的主机虚拟机地址(HVA)

再计算HVA, 主机虚拟地址,

```cpp
// 该section/fr所属的mr在分配的主机虚拟地址中的偏移(HVA) + 该块(section/fr)在所属mr中的偏移 + 
// 该块<fr/section>在虚拟机地址空间的起始地址(GPA)的对齐结果 - 该块<fr/section>在虚拟机地址空间的起始地址(GPA)
ram = memory_region_get_ram_ptr(mr) + section->offset_within_region +
          (start_addr - section->offset_within_address_space);
```

```cpp
// 返回该mr实际映射的主机虚拟机地址(因为可能是alias, 所以要加上offset)
void *memory_region_get_ram_ptr(MemoryRegion *mr)
{
    void *ptr;
    uint64_t offset = 0;
    RCU_READ_LOCK_GUARD();
    while (mr->alias) {
        // 别名mr在真实mr中的偏移
        offset += mr->alias_offset;
        // 找到真实的mr
        mr = mr->alias;
    }
    // ram_block 不能为空, 否则退出
    assert(mr->ram_block);
    // 返回block->host + offset, qemu分配的内存 + 偏移
    // offset是查找的mr在真实的mr中偏移, alias不与ram_block关联, 返回qemu分配的整个内存的一部分(属于该mr的)的起始地址, HVA
    ptr = qemu_map_ram_ptr(mr->ram_block, offset);
    return ptr;
}
```

### 5.1.4. kvm_set_user_memory_region(): 转化为slot然后注册到KVM

接下来是函数的重点处理部分, 即把**当前的section**转化成一个**slot**进行**添加**, 但是在此之前需要处理**已存在的slot**和**新的slot**的**重叠问题**, 当然如果没有重叠就好办了, 直接添加即可. 

```cpp
static int kvm_set_user_memory_region(KVMMemoryListener *kml, KVMSlot *slot, bool new)
{
    KVMState *s = kvm_state;
    struct kvm_userspace_memory_region mem;
    int ret;

    mem.slot = slot->slot | (kml->as_id << 16);
    // 虚拟机物理地址
    mem.guest_phys_addr = slot->start_addr;
    mem.userspace_addr = (unsigned long)slot->ram;
    mem.flags = slot->flags;

    if (slot->memory_size && !new && (mem.flags ^ slot->old_flags) & KVM_MEM_READONLY) {
        /* Set the slot size to 0 before setting the slot to the desired
         * value. This is needed based on KVM commit 75d61fbc. */
        mem.memory_size = 0;
        kvm_vm_ioctl(s, KVM_SET_USER_MEMORY_REGION, &mem);
    }
    mem.memory_size = slot->memory_size;
    ret = kvm_vm_ioctl(s, KVM_SET_USER_MEMORY_REGION, &mem);
    slot->old_flags = mem.flags;
    trace_kvm_set_user_memory(mem.slot, mem.flags, mem.guest_phys_addr,
                              mem.memory_size, mem.userspace_addr, ret);
    return ret;
}
```

```cpp
    // 
    ram = memory_region_get_ram_ptr(mr) + section->offset_within_region + delta;
    /*对重叠部分的处理*/
    while (1) {
        /*查找重叠的部分*/
        mem = kvm_lookup_overlapping_slot(s, start_addr, start_addr + size);
        /*如果没找到重叠, 就break*/
        if (!mem) {
            break;
        }
        /*如果要添加区间已经被注册*/
        if (add && start_addr >= mem->start_addr &&
            (start_addr + size <= mem->start_addr + mem->memory_size) &&
            (ram - start_addr == mem->ram - mem->start_addr)) {
            /* The new slot fits into the existing one and comes with
             * identical parameters - update flags and done. */
            kvm_slot_dirty_pages_log_change(mem, log_dirty);
            return;
        }

        old = *mem;

        if (mem->flags & KVM_MEM_LOG_DIRTY_PAGES) {
            kvm_physical_sync_dirty_bitmap(section);
        }
        /*移除重叠的部分*/
        /* unregister the overlapping slot */
        mem->memory_size = 0;
        err = kvm_set_user_memory_region(s, mem);
        if (err) {
            fprintf(stderr, "%s: error unregistering overlapping slot: %s\n",
                    __func__, strerror(-err));
            abort();
        }

        /* Workaround for older KVM versions: we can't join slots, even not by
         * unregistering the previous ones and then registering the larger
         * slot. We have to maintain the existing fragmentation. Sigh.
         *
         * This workaround assumes that the new slot starts at the same
         * address as the first existing one. If not or if some overlapping
         * slot comes around later, we will fail (not seen in practice so far)
         * - and actually require a recent KVM version. */
         /*如果已有的size小于申请的size, 则需要在原来的基础上, 添加新的, 不能删除原来的再次添加*/
        if (s->broken_set_mem_region &&
            old.start_addr == start_addr && old.memory_size < size && add) {
            mem = kvm_alloc_slot(s);
            mem->memory_size = old.memory_size;
            mem->start_addr = old.start_addr;
            mem->ram = old.ram;
            mem->flags = kvm_mem_flags(s, log_dirty, readonly_flag);

            err = kvm_set_user_memory_region(s, mem);
            if (err) {
                fprintf(stderr, "%s: error updating slot: %s\n", __func__,
                        strerror(-err));
                abort();
            }

            start_addr += old.memory_size;
            ram += old.memory_size;
            size -= old.memory_size;
            continue;
        }

        /* register prefix slot */
        /*new 的start_addr大于old.start_addr, 需要补足前面多余的部分*/
        if (old.start_addr < start_addr) {
            mem = kvm_alloc_slot(s);
            mem->memory_size = start_addr - old.start_addr;
            mem->start_addr = old.start_addr;
            mem->ram = old.ram;
            mem->flags =  kvm_mem_flags(s, log_dirty, readonly_flag);

            err = kvm_set_user_memory_region(s, mem);
            if (err) {
                fprintf(stderr, "%s: error registering prefix slot: %s\n",
                        __func__, strerror(-err));
#ifdef TARGET_PPC
                fprintf(stderr, "%s: This is probably because your kernel's " \
                                "PAGE_SIZE is too big. Please try to use 4k " \
                                "PAGE_SIZE!\n", __func__);
#endif
                abort();
            }
        }

        /* register suffix slot */
        /* old的size 大于 新申请的 */
        if (old.start_addr + old.memory_size > start_addr + size) {
            ram_addr_t size_delta;

            mem = kvm_alloc_slot(s);
            mem->start_addr = start_addr + size;
            size_delta = mem->start_addr - old.start_addr;
            mem->memory_size = old.memory_size - size_delta;
            mem->ram = old.ram + size_delta;
            mem->flags = kvm_mem_flags(s, log_dirty, readonly_flag);

            err = kvm_set_user_memory_region(s, mem);
            if (err) {
                fprintf(stderr, "%s: error registering suffix slot: %s\n",
                        __func__, strerror(-err));
                abort();
            }
        }
    }
```

首先调用了kvm_lookup_overlapping_slot函数找到一个冲突的slot, 注意返回结果是按照slot为单位, 只要两个地址范围有交叉, 就意味着存在冲突, 就返回冲突的slot. 如果没有, 那么直接break, 添加新的. 否则就根据以下几种情况进行分别处理. 其实主要由两种大情况: 

1、新的slot完全包含于引起冲突的slot中, 并且参数都是一致的. 

2、新的slot和引起冲突的slot仅仅是部分交叉. 

针对第一种情况, 如果flag有变动, 则只更新slot的flags,否则, 不需要变动. 第二种情况, 首先要把原来的region     delete掉, 具体方式是设置mem->memory_size=0,然后调用kvm_set_user_memory_region()函数. 由于 新的region和delete的region不是完全对应的, 仅仅是部分交叉, 所以就会连带 删除多余的映射, 那么接下来的工作就 是分批次弥补映射. 如图所示

![2020-02-28-23-33-06.png](./images/2020-02-28-23-33-06.png)

如图所示, old region是找到的和new region重叠的slot, 首次删除把整个slot都删除了, 造成了region1部门很无辜的受伤, 所以在映射时, 要把region1在弥补上. 而黑色部分就是实际删除的, 这样接下来就可以直接映射new region了, 如果多余的部分在后方, 也是同样的道理. 在把无辜被删除region映射之后, 接下来就调用kvm_set_user_memory_region把new slot映射进去. 基本思路就是这样. 

下面看下核心函数`kvm_set_user_memory_region`


```cpp
static int kvm_set_user_memory_region(KVMState *s, KVMSlot *slot)
{
    struct kvm_userspace_memory_region mem;
    // slot id
    mem.slot = slot->slot;
    // 虚拟机物理地址
    mem.guest_phys_addr = slot->start_addr;
    // 对应的qemu分配的内存, HVA
    mem.userspace_addr = (unsigned long)slot->ram;
    mem.flags = slot->flags;
    if (s->migration_log) {
        mem.flags |= KVM_MEM_LOG_DIRTY_PAGES;
    }
    // 只读的mem
    if (slot->memory_size && mem.flags & KVM_MEM_READONLY) {
        /* Set the slot size to 0 before setting the slot to the desired
         * value. This is needed based on KVM commit 75d61fbc. */
        mem.memory_size = 0;
        kvm_vm_ioctl(s, KVM_SET_USER_MEMORY_REGION, &mem);
    }
    // 内存大小
    mem.memory_size = slot->memory_size;
    return kvm_vm_ioctl(s, KVM_SET_USER_MEMORY_REGION, &mem);
}
```

可以看到该函数实现也并不复杂, 使用了一个`kvm_userspace_memory_region`对应, 该结构本质上作为参数传递给KVM, 只是由于不能共享堆栈, 在KVM中需要把该结构复制到内核空间, 代码本身没什么难度, 只是这里如果是**只读的mem**, 需要**调用两次**kvm_vm_ioctl, 第一次设置mem的size为0. 

至于为何这么做, 可以参考KVM端说明, KVM接收端在`kvm_vm_ioctl()`函数中.

# 6. MMIO退出的处理

由于 mmio 导致的退出, `kvm_cpu_exec --> case KVM_EXIT_MMIO --> address_spaces_rw --> address_space_rw --> io_mem_write`

```cpp
int kvm_cpu_exec(CPUState *cpu)
{
    ......
    do {
        run_ret = kvm_vcpu_ioctl(cpu, KVM_RUN, 0);
        attrs = kvm_arch_post_run(cpu, run);
        switch (run->exit_reason) {
            case KVM_EXIT_MMIO:
                address_space_rw(&address_space_memory,
                                run->mmio.phys_addr, attrs,
                                run->mmio.data,
                                run->mmio.len,
                                run->mmio.is_write);
        }
    }
    ......
}
```

```cpp
MemTxResult address_space_rw(AddressSpace *as, hwaddr addr, MemTxAttrs attrs,
                             uint8_t *buf, hwaddr len, bool is_write)
{
    if (is_write) {
        return address_space_write(as, addr, attrs, buf, len);
    } else {
        return address_space_read_full(as, addr, attrs, buf, len);
    }
}
```

```cpp
MemTxResult address_space_read_full(AddressSpace *as, hwaddr addr,
                                    MemTxAttrs attrs, uint8_t *buf, hwaddr len)
{
    MemTxResult result = MEMTX_OK;
    FlatView *fv;

    if (len > 0) {
        RCU_READ_LOCK_GUARD();
        fv = address_space_to_flatview(as);
        result = flatview_read(fv, addr, attrs, buf, len);
    }

    return result;
}

MemTxResult address_space_write(AddressSpace *as, hwaddr addr,
                                MemTxAttrs attrs,
                                const uint8_t *buf, hwaddr len)
{
    MemTxResult result = MEMTX_OK;
    FlatView *fv;

    if (len > 0) {
        RCU_READ_LOCK_GUARD();
        fv = address_space_to_flatview(as);
        result = flatview_write(fv, addr, attrs, buf, len);
    }

    return result;
}
```

# 7. 总结

qemu向KVM注册内存的流程:

![2020-04-18-17-58-12.png](./images/2020-04-18-17-58-12.png)

1. 全局MemoryRegion: system_memory以及system_io的初始化

![2020-03-12-15-20-57.png](./images/2020-03-12-15-20-57.png)

2. GPA (guest physical address) 与HVA (host virtual address)的公共代码的分析. 

3. 内存发生变化时, 更新内存映射 (GPA-HVA-HPA). 

![2020-03-12-15-21-29.png](./images/2020-03-12-15-21-29.png)

4. `x86_64`内存初始化的代码分析

![2020-03-12-15-23-07.png](./images/2020-03-12-15-23-07.png)

5. 对上述x86_64的`memory_region_init_alias()`画图描述: 

![2020-03-01-00-23-18.png](./images/2020-03-01-00-23-18.png)

6. 上述x86_64 ram的`memory_region_add_subregion_common()`

![2020-03-01-00-23-42.png](./images/2020-03-01-00-23-42.png)

7. KVM_SET_USER_MEMORY_REGION的调用过程

![2020-03-12-15-26-11.png](./images/2020-03-12-15-26-11.png)

8. flatviews_reset()函数解析

![2020-03-12-15-26-29.png](./images/2020-03-12-15-26-29.png)

9. address_space_set_flatview()函数解析

![2020-03-12-15-27-27.png](./images/2020-03-12-15-27-27.png)

10. address_space_update_topology_pass => region_add()

![2020-03-12-15-27-49.png](./images/2020-03-12-15-27-49.png)

# 8. 参考

https://www.cnblogs.com/ck1020/p/6729224.html (已完)

https://www.cnblogs.com/ck1020/p/6738116.html (已完)

https://blog.csdn.net/Shirleylinyuer/article/details/83592758 (未整理)

http://abcdxyzk.github.io/blog/2015/07/29/kvm-src2/ (未完)

https://blog.csdn.net/woai110120130/article/details/102311622 (未完)

https://blog.csdn.net/leoufung/article/details/48781185 (未整理)

https://abelsu7.top/2019/07/07/kvm-memory-virtualization/ (未完)