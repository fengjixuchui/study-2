
# 概述

Linux 内核设备驱动充分利用了 "一切皆文件" 的思想, VFIO 驱动也不例外, VFIO 中为了方便操作 **device**, **group**, **container** 等对象, 将它们和对应的设备文件进行绑定.

VFIO提供了两个字符设备文件作为提供给用户程序的入口点,分别是 `/dev/vfio/vfio` 和 `/dev/vfio/$GROUP`, 此外还在sysfs中添加了一些文件.

首先看 `/dev/vfio/vfio`, 它是一个 misc device,在 vfio 模块的初始化函数 vfio_init 中注册:

```
# ll /dev/vfio/vfio
crw-rw-rw- 1 root root 10, 196 9月   8 02: 37 /dev/vfio/vfio
```

```cpp
// drivers/vfio/vfio_main.c
static struct miscdevice vfio_dev = {
	.minor = VFIO_MINOR,
	.name = "vfio",
	.fops = &vfio_fops,
	.nodename = "vfio/vfio",
	.mode = S_IRUGO | S_IWUGO,
};

static int __init vfio_init(void)
{
    int ret;
    /* ... */
    ret = misc_register(&vfio_dev);
    /* ... */
}
```

每次打开 `/dev/vfio/vfio` 文件,都会创建一个对应的 Container 即 `struct vfio_container`

```cpp
// qemu
s->container = open("/dev/vfio/vfio", O_RDWR);

// drivers/vfio/vfio_main.c
struct vfio_container {
	struct kref			kref;
    // vfio group 链表
	struct list_head		group_list;
	struct rw_semaphore		group_lock;
    // 关联的 iommu_driver, 通过 container 可以进行 IOMMU 相关的操作
	struct vfio_iommu_driver	*iommu_driver;
    // iommu driver 的相关数据
	void				*iommu_data;
	bool				noiommu;
};
```

我们可以将 vfio group 加入到 Container 中, Container 维护了一个vfio group(`struct vfio_group`)的链表 `group_list`. **Container 的作用!!!**就是通过其 `iommu_driver` **为加入的所有 group 提供 IOMMU 的服务**:

```cpp
struct vfio_iommu_driver {
	const struct vfio_iommu_driver_ops	*ops;
	struct list_head			vfio_next;
};
```

> noiommu 用于表示该 Container 是否用于存放 no-iommu 的 Group(一个 Container 不能同时存放到 no-iommu Group 和普通 Group). no-iommu Group 即背后没有 IOMMU 但仍然强行建立的 vfio group, 这个高级特性(`CONFIG_VFIO_NOIOMMU`)通常不建议开启, 我们忽略相关的代码即可.

`/dev/vfio/$GROUP` 文件显然对应着 vfio group,它的由来要更复杂一些,我们看vfio_init的一段代码来理解:

```cpp
#define MINORBITS	20
#define MINORMASK	((1U << MINORBITS) - 1)

// drivers/vfio/vfio_main.c
static int __init vfio_init(void)
{
    ......
    /* /dev/vfio/$GROUP */
	vfio.class = class_create(THIS_MODULE, "vfio");
	if (IS_ERR(vfio.class)) {
		ret = PTR_ERR(vfio.class);
		goto err_class;
	}

	vfio.class->devnode = vfio_devnode;

	ret = alloc_chrdev_region(&vfio.group_devt, 0, MINORMASK + 1, "vfio");
	if (ret)
		goto err_alloc_chrdev;

    cdev_init(&vfio.group_cdev, &vfio_group_fops);
    ret = cdev_add(&vfio.group_cdev, vfio.group_devt, MINORMASK + 1);
    if (ret)
        goto err_cdev_add;
    ......
}
```

其中 vfio_devnode 函数的定义如下:

```cpp
/*
 * Module/class support
 */
static char *vfio_devnode(struct device *dev, umode_t *mode)
{
	return kasprintf(GFP_KERNEL, "vfio/%s", dev_name(dev));
}
```

这里为 vfio group 字符设备动态分配了一整个 Major(即包含该Major下的所有 Minor)的设备号并注册了cdev, 一旦创建一个带devt的Device, vfio class(`/sys/class/vfio`)下, 就会创建一个 `/dev/vfio/$GROUP` 字符设备文件.

VFIO 分为 VFIO 核心模块和 VFIO 驱动模块, VFIO Group 是由 VFIO 驱动模块创建的, 最常用的是 vfio-pci 驱动. VFIO 驱动是以设备驱动的形式实现, 它们会注册一个 Driver, 并在其 probe 函数中调用 vfio_add_group_dev, 并最终会调用 device_create 为 VFIO Group 创建一个 Device(从而也创建了 `/dev/vfio/$GROUP` 设备文件):

```cpp
    /* vfio_add_group_dev --> vfio_create_group */
    dev = device_create(vfio.class, NULL,
            MKDEV(MAJOR(vfio.group_devt), minor),
            group, "%s%d", group->noiommu ? "noiommu-" : "",
            iommu_group_id(iommu_group));
```

至于上面说的sysfs文件,也是由VFIO驱动创建的,因为它本身就是一个(虚拟)设备驱动,自然可以创建sysfs目录与属性.

# 1. vfio_container

> **Container 的作用!!!**就是通过其 `iommu_driver` **为加入的所有 group 提供 IOMMU 的服务** 

vfio container 和 vfio group 不同.

* **vfio container** 只有一个入口点即 `/dev/vfio/vfio`, 每次打开该设备文件, 都将获得一个新的 vfio container 实例.

* **vfio group** 和 `/dev/vfio/$GROUP` **设备文件**绑定, 每个设备文件唯一对应**一个vfio group**, 且**只能打开一次**, 试图第二次打开会返回 `-EBUSY`.

container fd 对应的 ioctl 接口如下:

```cpp
static long vfio_fops_unl_ioctl(struct file *filep,
				unsigned int cmd, unsigned long arg)
{
	struct vfio_container *container = filep->private_data;
	struct vfio_iommu_driver *driver;
	void *data;
	long ret = -EINVAL;

	if (!container)
		return ret;

	switch (cmd) {
	case VFIO_GET_API_VERSION:
		ret = VFIO_API_VERSION;
		break;
	case VFIO_CHECK_EXTENSION:
		ret = vfio_ioctl_check_extension(container, arg);
		break;
	case VFIO_SET_IOMMU:
		ret = vfio_ioctl_set_iommu(container, arg);
		break;
	default:
		driver = container->iommu_driver;
		data = container->iommu_data;
        // 其他 ioctl 都是 iommu_driver 的
		if (driver) /* passthrough all unrecognized ioctls */
			ret = driver->ops->ioctl(data, cmd, arg);
	}

	return ret;
}
```

## container的API

vfio container 本身具备的功能很小, 只有三个 ioctl:

* `VFIO_GET_API_VERSION`, 返回VFIO_API_VERSION(目前版本号为0)

* `VFIO_CHECK_EXTENSION`, 用来检测是否支持特定的扩展, 如支持哪种类型的 IOMMU

* `VFIO_SET_IOMMU`, 设置 **IOMMU Driver** 的类型, 指定的IOMMU必须是通过 `VFIO_CHECK_EXTENSION` 确认驱动支持的. 在调用该 ioctl 前**必须至少挂载一个 vfio group**

    * IOMMU driver 本质上只有**两种类型**, 即 **Type1 IOMMU** 和 **sPAPR IOMMU**, 前者代表 x86,ARM 等架构上的 IOMMU, 后者代表 POWER 架构上的 IOMMU

    * **Type1 IOMMU**, 又细分为 `VFIO_TYPE1_IOMMU`, `VFIO_TYPE1v2_IOMMU` 和 `VFIO_TYPE1_NESTING_IOMMU`, 一般来说用 `VFIO_TYPE1v2_IOMMU` 即可

    * 所有的 type 都可以作为 `VFIO_CHECK_EXTENSION` 的**参数**, 检查内核是否支持该类型, 用户应该**先检查是否支持该类型**再设置 IOMMU Driver

## iommu driver的API

上一节也说过(上面结构体也说明), container 会与 iommu_driver 联系起来, 这样通过 container 可以进行 IOMMU 相关的操作. 以 type1 iommu driver 说明

### 外部接口

vfio container 上的其余操作都会代理给其 IOMMU Driver 执行, 包括read,write,mmap 和上述三个 ioctl 以外的 ioctl.

```cpp
/* vfio_fops_read */
driver = container->iommu_driver;
if (likely(driver && driver->ops->read))
    ret = driver->ops->read(container->iommu_data,
                buf, count, ppos);

/* vfio_fops_write */
driver = container->iommu_driver;
if (likely(driver && driver->ops->write))
    ret = driver->ops->write(container->iommu_data,
                 buf, count, ppos);

/* vfio_fops_mmap */
driver = container->iommu_driver;
if (likely(driver && driver->ops->mmap))
    ret = driver->ops->mmap(container->iommu_data, vma);

/* vfio_fops_unl_ioctl */
default:
    driver = container->iommu_driver;
    data = container->iommu_data;

    if (driver) /* passthrough all unrecognized ioctls */
        ret = driver->ops->ioctl(data, cmd, arg);
```

另外, `VFIO_CHECK_EXTENSION` 实际上也是代理给 IOMMU Driver 执行的, 当 Container 尚未指定 Driver 时, 是遍历系统中的 IOMMU Driver 依次调用 `VFIO_CHECK_EXTENSION`, 至少有一个返回 1 则最终返回 1, 否则返回 0, 当 Container 指定了 Driver 时, 则对该 Driver 调用 `FIO_CHECK_EXTENSION`.

对于我们关心的Type 1 IOMMU Driver,其提供的重要的 ioctl 实际上有

* `VFIO_IOMMU_GET_INFO`: 用来得到 IOMMU 的一些信息, 这个 ioctl 只针对 Type1 的 IOMMU.

* `VFIO_CHECK_EXTENSION`, 当前 iommu_driver 的检查

* `VFIO_IOMMU_MAP_DMA`: 用来指定**设备端**看到的 **IO 地址**到**进程的虚拟地址**之间的映射, 类似于KVM中的 `KVM_SET_USER_MEMORY_REGION` 指定虚拟机物理地址到进程虚拟地址之间的映射.

会传入一个 `struct vfio_iommu_type1_dma_map`:

```cpp
struct vfio_iommu_type1_dma_map {
    __u32   argsz;
    __u32   flags;
#define VFIO_DMA_MAP_FLAG_READ (1 << 0)     /* readable from device */
#define VFIO_DMA_MAP_FLAG_WRITE (1 << 1)    /* writable from device */
    __u64   vaddr;                          /* Process virtual address */
    __u64   iova;                           /* IO virtual address */
    __u64   size;                           /* Size of mapping (bytes) */
};
```

* `VFIO_IOMMU_UNMAP_DMA`: 传入一个 `struct vfio_iommu_type1_dma_unmap`, 成功 unmap 的内存的 size 会在 size 中返回(可能比传入的 size 小):

```cpp
struct vfio_iommu_type1_dma_unmap {
    __u32   argsz;
    __u32   flags;
    __u64   iova;               /* IO virtual address */
    __u64   size;               /* Size of mapping (bytes) */
};
```

这里设置的 DMA Remapping 是针对整个 Container, 即针对其中的所有 Group 的, 下面我们将详细讨论这一点.

### 内部接口

IOMMU Driver 实际上只是一个接口，用于提供若干回调，与具体的实现解耦：

```cpp
struct vfio_iommu_driver {
    const struct vfio_iommu_driver_ops  *ops;
    struct list_head                    vfio_next;
};

/**
 * struct vfio_iommu_driver_ops - VFIO IOMMU driver callbacks
 */
struct vfio_iommu_driver_ops {
    char            *name;
    struct module   *owner;
    void            *(*open)(unsigned long arg);
    void            (*release)(void *iommu_data);
    ssize_t         (*read)(void *iommu_data, char __user *buf,
                            size_t count, loff_t *ppos);
    ssize_t         (*write)(void *iommu_data, const char __user *buf,
                             size_t count, loff_t *size);
    long            (*ioctl)(void *iommu_data, unsigned int cmd,
                             unsigned long arg);
    int             (*mmap)(void *iommu_data, struct vm_area_struct *vma);
    int	            (*attach_group)(void *iommu_data,
                                    struct iommu_group *group);
    void            (*detach_group)(void *iommu_data,
                                    struct iommu_group *group);
    int             (*pin_pages)(void *iommu_data, unsigned long *user_pfn,
                                 int npage, int prot,
                                 unsigned long *phys_pfn);
    int             (*unpin_pages)(void *iommu_data,
                                   unsigned long *user_pfn, int npage);
    int             (*register_notifier)(void *iommu_data,
                                         unsigned long *events,
                                         struct notifier_block *nb);
    int             (*unregister_notifier)(void *iommu_data,
                                           struct notifier_block *nb);
};
```





# 2. vfio_group

当我们把一个设备直通给虚拟机时, 首先要做的就是将这个设备从 host 上进行解绑, 即**解除 host 上此设备的驱动**, 然后**将设备驱动绑定**为 "`vfio-pci`", 在完成绑定后会新增一个 `/dev/vfio/$groupid` 的文件, 其中 `$groupid` 为此 PCI 设备的 **iommu group id**, 这个 id 号是在操作系统加载 iommu driver 遍历扫描 host 上的 PCI 设备的时候就已经分配好的, 可以使用 `readlink -f /sys/bus/pci/devices/$bdf/iommu_group` 来查询.

类似的, `/dev/vfio/$groupid` 这个文件的句柄被关联到 **vfio_group** 上, **用户态进程**打开这个文件就可以**管理这个 iommu group 里的设备**.

```
# ll /dev/vfio/
total 0
drwxr-xr-x  2 root root       80 9月   8 02: 47 ./
drwxr-xr-x 18 root root     4580 9月   8 02: 47 ../
crw-------  1 root root 244,   0 9月   8 02: 47 21
crw-rw-rw-  1 root root  10, 196 9月   8 02: 37 vfio

# ll /sys/bus/pci/devices/0000\: 01\: 00.0/iommu_group
lrwxrwxrwx 1 root root 0 9月   8 02: 37 /sys/bus/pci/devices/0000: 01: 00.0/iommu_group -> ../. ./. ./. ./kernel/iommu_groups/21/
# readlink -f /sys/bus/pci/devices/0000\: 01\: 00.0/iommu_group
/sys/kernel/iommu_groups/21
```

# 3. device

然而 VFIO 中并**没有**为**每个 device** 单独创建一个文件, 而是通过 `VFIO_GROUP_GET_DEVICE_FD` 来调用这个 group ioctl 来**获取 device 的句柄**, 然后再通过这个句柄来管理设备.

> VFIO_GROUP_GET_DEVICE_FD: vfio 从 group->device_list 中查找device, 并通过匿名node和fd建立关系

# 4. vfio_iommu_driver

VFIO 框架中很重要的一部分是要完成 **DMA Remapping**, 即为 **Domain** 创建对应的 **IOMMU 页表**, 这个部分是由 `vfio_iommu_driver` 来完成的.

**vfio_container** 包含一个指针记录 **vfio_iommu_driver** 的信息, 在 x86 上 `vfio_iommu_driver` 的具体实现是由 **vfio_iommu_type1** 模块来完成的.

```cpp
struct vfio_container {
        struct kref                     kref;
        struct list_head                group_list;
        struct rw_semaphore             group_lock;
        struct vfio_iommu_driver        *iommu_driver;
        void                            *iommu_data;
        bool                            noiommu;
};
```

```
│ Symbol: VFIO_IOMMU_TYPE1 [=y]
│ Type  : tristate
│ Defined at drivers/vfio/Kconfig:2
│   Depends on: VFIO [=y]
│ Selected by [y]:
│   - VFIO [=y] && MMU [=y] && (X86 [=y] || S390 || ARM || ARM64)
```

**vfio_iommu_type1** 模块包含了 `vfio_iommu`, `vfio_domain`, `vfio_group`, `vfio_dma` 等关键数据结构.

```
// drivers/vfio/vfio_iommu_type1.c
vfio_iommu : struct
vfio_domain : struct
vfio_dma : struct
vfio_batch : struct
vfio_iommu_group : struct
vfio_iova : struct
vfio_pfn : struct
vfio_regions : struct
```

* **vfio_iommu** 可以认为是和 **container** 概念相对应的 iommu 数据结构, 在虚拟化场景下**每个虚拟机的物理地址空间**映射到一个 `vfio_iommu` 上.

* **vfio_group** 可以认为是和 **group** 概念对应的 iommu 数据结构, 它指向一个 `iommu_group` 对象, 记录了着 `iommu_group` 的信息.

* **vfio_domain** 这个概念尤其需要注意, 这里绝**不能**把它理解成**一个虚拟机 domain**, 它是一个与 **DRHD**(即 IOMMU 硬件)相关的概念, 它的出现就是**为了应对多 IOMMU 硬件的场景**, 我们知道在大规格服务器上可能会有**多个 IOMMU 硬件**, 不同的 IOMMU **硬件有可能存在差异**, 例如 IOMMU 0 支持 `IOMMU_CACHE`, 而 IOMMU 1 不支持 IOMMU_CACHE(当然这种情况少见, 大部分平台上硬件功能是具备一致性的), 这时候我们**不能**直接将分别**属于不同 IOMMU 硬件管理的设备**直接加入到**一个 container** 中, 因为它们的 IOMMU 页表 SNP bit 是不一致的. 因此, 一种合理的解决办法就是把**一个 container** 划分**多个 vfio_domain**, 当然在大多数情况下我们只需要一个 vfio_domain 就足够了. 处在**同一个 vfio_domain 中的设备共享 IOMMU 页表区域**, 不同的 vfio_domain 的页表属性又可以不一致, 这样我们就可以支持跨 IOMMU 硬件的设备直通的混合场景.

```
# ll /sys/class/iommu/
total 0
drwxr-xr-x  2 root root 0 Sep 19 09: 09 ./
drwxr-xr-x 76 root root 0 Sep 19 09: 09 ../
lrwxrwxrwx  1 root root 0 Sep 19 09: 09 dmar0 -> ../. ./devices/virtual/iommu/dmar0/
lrwxrwxrwx  1 root root 0 Sep 19 09: 09 dmar1 -> ../. ./devices/virtual/iommu/dmar1/
```

# 5. 小结

经过上面的介绍和分析, 我们可以把 VFIO 各个组件直接的关系用下图表示.

![2022-08-18-16-02-53.png](./images/2022-08-18-16-02-53.png)

![2022-08-16-22-08-04.png](./images/2022-08-16-22-08-04.png)

对这些的用户态代码可以看 qemu 或 kvmtool(更简单)


