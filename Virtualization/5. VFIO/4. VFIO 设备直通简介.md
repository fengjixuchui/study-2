
<!-- @import "[TOC]" {cmd="toc" depthFrom=1 depthTo=6 orderedList=false} -->

<!-- code_chunk_output -->

- [1. VFIO 和 VT-d](#1-vfio-和-vt-d)
- [2. VFIO 框架简介](#2-vfio-框架简介)
  - [2.1. vfio interface](#21-vfio-interface)
  - [2.2. vfio_iommu 和 vfio_pci](#22-vfio_iommu-和-vfio_pci)
  - [2.3. iommu driver 和 pci bus driver](#23-iommu-driver-和-pci-bus-driver)
  - [2.4. 示例](#24-示例)
- [3. 三个核心概念](#3-三个核心概念)
  - [3.1. Device](#31-device)
  - [3.2. Group](#32-group)
  - [3.3. Container](#33-container)
  - [3.4. 三个的关系](#34-三个的关系)
- [4. VFIO 数据结构](#4-vfio-数据结构)
  - [4.1. vfio_container](#41-vfio_container)
  - [4.2. vfio_group](#42-vfio_group)
  - [4.3. device](#43-device)
  - [4.4. vfio_iommu_driver](#44-vfio_iommu_driver)
  - [4.5. 小结](#45-小结)
- [5. VFIO 中的技术关键点](#5-vfio-中的技术关键点)

<!-- /code_chunk_output -->

# 1. VFIO 和 VT-d

Virtual Function I/O (VFIO) 是一种现代化的设备直通方案, 它充分利用了 `VT-d`/`AMD-Vi` 技术提供的 `DMA Remapping` 和 `Interrupt Remapping` 特性, 在保证直通设备的 DMA 安全性同时可以达到接近物理设备的 I/O 的性能. **用户态进程**可以直接使用 VFIO 驱动直接访问硬件, 并且由于整个过程是在 IOMMU 的保护下进行因此十分安全, 而且非特权用户也是可以直接使用. 换句话说, **VFIO** 是一套完整的**用户态驱动** (userspace driver) 方案, 因为它可以安全地把设备 I/O, 中断, DMA 等能力呈现给用户空间.

为了达到最高的 IO 性能, 虚拟机就需要 VFIO 这种设备直通方式, 因为它具有低延时, 高带宽的特点, 并且 guest 也能够直接使用设备的原生驱动. 这些优异的特点得益于 VFIO 对 `VT-d`/`AMD-Vi` 所提供的 DMA Remapping 和 Interrupt Remapping 机制的应用.

* VFIO 使用 **DMA Remapping** 为 **每个 Domain** 建立独立的 `IOMMU Page Table` 将直通设备的 DMA 访问限制在 **Domain 的地址空间之内**, 从而保证了用户态 DMA 的安全性
* 使用 `Interrupt Remapping` 来完成**中断重映射**和 `Interrupt Posting` 来达到 **中断隔离** 和 **中断直接投递** 的目的.

# 2. VFIO 框架简介

整个 VFIO 框架设计十分简洁清晰, 可以用下面的一幅图描述:

```
+-------------------------------------------+
|                                           |
|             VFIO Interface                |
|                                           |
+---------------------+---------------------+
|                     |                     |
|     vfio_iommu      |      vfio_pci       |
|                     |                     |
+---------------------+---------------------+
|                     |                     |
|    iommu driver     |    pci_bus driver   |
|                     |                     |
+---------------------+---------------------+
```

## 2.1. vfio interface

最上层的是 `VFIO Interface Layer`, 它负责**向用户态**提供**统一访问的接口**, 用户态通过约定的 **ioctl** (`/dev/vfio/vfio`) 来设置和调用 VFIO 的各种能力.

```
# ll /dev/vfio/vfio
crw-rw-rw- 1 root root 10, 196 9月   8 02: 37 /dev/vfio/vfio
```

```cpp
// drivers/vfio/vfio.c
static struct miscdevice vfio_dev = {
        .minor = VFIO_MINOR,
        .name = "vfio",
        .fops = &vfio_fops,
        .nodename = "vfio/vfio",
        .mode = S_IRUGO | S_IWUGO,
};

static const struct file_operations vfio_fops = {
        .owner          = THIS_MODULE,
        .open           = vfio_fops_open,
        .release        = vfio_fops_release,
        .read           = vfio_fops_read,
        .write          = vfio_fops_write,
        .unlocked_ioctl = vfio_fops_unl_ioctl,
        .compat_ioctl   = compat_ptr_ioctl,
        .mmap           = vfio_fops_mmap,
};
```

## 2.2. vfio_iommu 和 vfio_pci

中间层分别是 `vfio_iommu` 和 `vfio_pci`

* **vfio_iommu** 是 VFIO **对 iommu 层的统一封装**主要用来实现 **DMAP Remapping** 的功能, 即**管理 IOMMU 页表**的能力.

```cpp
// drivers/vfio/vfio_iommu_type1.c
static const struct vfio_iommu_driver_ops vfio_iommu_driver_ops_type1 = {
        ......
        .release                = vfio_iommu_type1_release,
        .ioctl                  = vfio_iommu_type1_ioctl,
        .pin_pages              = vfio_iommu_type1_pin_pages,
        .dma_rw                 = vfio_iommu_type1_dma_rw,
        ......
}

static int __init vfio_iommu_type1_init(void)
{
        return vfio_register_iommu_driver(&vfio_iommu_driver_ops_type1);
}
module_init(vfio_iommu_type1_init);
```

* **vfio_pci** 是 VFIO **对 pci 设备驱动的统一封装**, 它和**用户态进程**一起配合完成**设备访问直接访问**, 具体包括 **PCI 配置空间模拟**, **PCI Bar 空间重定向**, **Interrupt Remapping** 等.

```cpp
// drivers/vfio/pci/vfio_pci.c
static const struct vfio_device_ops vfio_pci_ops = {
        .name           = "vfio-pci",
        .open_device    = vfio_pci_open_device,
        .close_device   = vfio_pci_core_close_device,
        .ioctl          = vfio_pci_core_ioctl,
        .read           = vfio_pci_core_read,
        .write          = vfio_pci_core_write,
        .mmap           = vfio_pci_core_mmap,
        .request        = vfio_pci_core_request,
        .match          = vfio_pci_core_match,
};
```

```
  │ Symbol: VFIO_PCI [=m]                                                                                        │
  │ Type  : tristate                                                                                             │
  │ Defined at drivers/vfio/pci/Kconfig:2                                                                        │
  │   Prompt: VFIO support for PCI devices                                                                       │
  │   Depends on: VFIO [=y] && PCI [=y] && EVENTFD [=y] && MMU [=y]                                              │
  │   Location:                                                                                                  │
  │     -> Device Drivers                                                                                        │
  │ (1)   -> VFIO Non-Privileged userspace driver framework (VFIO [=y])                                          │
  │ Selects: VFIO_VIRQFD [=m] && IRQ_BYPASS_MANAGER [=m] 

  │ Symbol: PCIE_BUS_DEFAULT [=y]                                                                                │
  │ Type  : bool                                                                                                 │
  │ Defined at drivers/pci/Kconfig:218                                                                           │
  │   Prompt: Default                                                                                            │
  │   Depends on: <choice> && PCI [=y]                                                                           │
  │   Location:                                                                                                  │
  │     -> Device Drivers                                                                                        │
  │       -> PCI support (PCI [=y])                                                                              │
  │ (1)     -> PCI Express hierarchy optimization setting (<choice> [=y]) 
```

## 2.3. iommu driver 和 pci bus driver

最下面的一层则是**硬件驱动调用层**

* **iommu driver** 是与**硬件平台相关的实现**, 例如它可能是 `intel iommu driver` 或 `amd iommu driver` 或者 `ppc iommu driver`

```cpp
// drivers/iommu/intel/iommu.c
const struct iommu_ops intel_iommu_ops = {
        .capable                = intel_iommu_capable,
        .domain_alloc           = intel_iommu_domain_alloc,
        .domain_free            = intel_iommu_domain_free,
        ......
}
```

* **vfio_pci** 会调用到 host 上的 **pci_bus driver** 来实现**设备的注册和反注册**等操作. 仅仅调用了注册/反注册逻辑??

```cpp
// drivers/pci/bus.c

```

## 2.4. 示例

1. `vfio_iommu_driver` -> `iommu driver` -> `intel iommu driver`

* `"drivers/vfio/vfio_iommu_type1.c"` -> `"drivers/iommu/iommu.c"` -> `"drivers/iommu/intel/iommu.c"`

* `release()` -> `vfio_iommu_type1_release()` -> `vfio_release_domain()` -> `iommu_domain_free()` -> `domain->ops->domain_free(domain)` -> `intel_iommu_domain_free()`

2. 

`"drivers/pci/pci-driver.c"` -> `drivers/pci/bus.c`

`vfio_pci_probe()` -> `vfio_pci_core_register_device()`

`vfio_pci_bus_notifier()` 

`pci_device_probe()` ->

# 3. 三个核心概念

![2021-09-18-15-36-52.png](./images/2021-09-18-15-36-52.png)

在了解 VFIO 之前需要了解 3 个基本概念: device, group, container, 它们在逻辑上的关系如上图所示.

## 3.1. Device

* **Device** 指的是我们要操作的硬件设备, 不过这里的 "设备" 需要从 **IOMMU 拓扑**的角度去理解.

  * 如果该设备是**硬件拓扑上一个独立的设备**, 那么它**自己就构成一个 iommu group**.
  * 如果这里是一个 **multi-function 设备**, 那么它和其他的 function **一起组成**一个 **iommu group**.

> 因为**多个 function 设备在物理硬件上就是互联的**, 他们可以**互相访问对方的数据**, 所以必须放到一个 group 里隔离起来.
> 
> 也就是说一个 group 就是 BDF 中的 BD 相同的 device 集合
>
> 值得一提的是, 对于**支持 PCIe ACS 特性**的硬件设备, 我们可以认为他们在物理上是互相隔离的.

```
# tree /sys/kernel/iommu_groups/
/sys/kernel/iommu_groups/
├── 0
│   ├── devices
│   │   └── 0000: 00: 00.0 -> ../. ./. ./. ./devices/pci0000: 00/0000: 00: 00.0
│   ├── reserved_regions
│   └── type
......
├── 11
│   ├── devices
│   │   ├── 0000: 00: 0d.0 -> ../. ./. ./. ./devices/pci0000: 00/0000: 00: 0d.0
│   │   ├── 0000: 00: 0d.2 -> ../. ./. ./. ./devices/pci0000: 00/0000: 00: 0d.2
│   │   └── 0000: 00: 0d.3 -> ../. ./. ./. ./devices/pci0000: 00/0000: 00: 0d.3
│   ├── reserved_regions
│   └── type

# lspci
00: 0d.0 USB controller: Intel Corporation Device 9a13 (rev 01)
00: 0d.2 USB controller: Intel Corporation Device 9a1b (rev 01)
00: 0d.3 USB controller: Intel Corporation Device 9a1d (rev 01)
......
```

## 3.2. Group

* **Group** 是 **IOMMU** 能够进行 **DMA 隔离的最小硬件单元**, 一个 group 内可能只有一个 device, 也可能有**多个 device**, 这取决于**物理平台**上**硬件的 IOMMU 拓扑结构**. 设备直通的时候一个 group 里面的设备必须都直通给一个虚拟机.

> 不能够让一个 group 里的多个 device 分别从属于 2 个不同的 VM, 也不允许部分 device 在 host 上而另一部分被分配到 guest 里, 因为这样一个 guest 中的 device 可以利用 DMA 攻击获取另外一个 guest 里的数据, 就无法做到物理上的 DMA 隔离.
> 
> 另外, **VFIO 中的 group** 和 **iommu group** 可以认为是同一个概念.

## 3.3. Container

* **Container** 是一个**和地址空间相关联**的概念, 这里可以简单把它理解为**一个 VM Domain 的物理内存空间**.

> DMA Isolation 是以 Domain 为单位进行隔离的. **每个 VM 的地址空间称为一个 Domain**.

## 3.4. 三个的关系

从上图可以看出:

1. 一个或**多个 device** 从属于**某个 group**
2. 而一个或**多个 group** 又从属于**一个 container**, 这些group共享页表信息.

如果要**将一个 device 直通给 VM**, 那么先要找到**这个设备从属的 iommu group**, 然后将整个 group 加入到 **container** 中即可.

关于如何使用 VFIO 可以参考内核文档: [vfio.txt](https://www.kernel.org/doc/Documentation/vfio.txt)

# 4. VFIO 数据结构

Linux 内核设备驱动充分利用了 "一切皆文件" 的思想, VFIO 驱动也不例外, VFIO 中为了方便操作 **device**, **group**, **container** 等对象, 将它们和对应的设备文件进行绑定. 

## 4.1. vfio_container

VFIO Container和VFIO Group不同。VFIO Group和/dev/vfio/$GROUP设备文件绑定，每个设备文件唯一对应一个VFIO Group，且只能打开一次，试图第二次打开会返回`-EBUSY`。

**VFIO 驱动**在加载的时候会创建一个名为 `/dev/vfio/vfio` 的文件.

VFIO Container只有一个入口点即/dev/vfio/vfio，每次打开该设备文件，都将获得一个新的VFIO Container实例.

```cpp
// drivers/vfio/vfio.c
static const struct file_operations vfio_fops = {
        ......
        .open           = vfio_fops_open,
        ......
}

static int vfio_fops_open(struct inode *inode, struct file *filep)
{
        struct vfio_container *container;

        container = kzalloc(sizeof(*container), GFP_KERNEL);
        if (!container)
                return -ENOMEM;

        INIT_LIST_HEAD(&container->group_list);
        init_rwsem(&container->group_lock);
        kref_init(&container->kref);

        filep->private_data = container;

        return 0;
}
```

```cpp
// qemu
s->container = open("/dev/vfio/vfio", O_RDWR);
```

VFIO Container本身具备的功能微乎其微，只有三个ioctl：

* VFIO_GET_API_VERSION，返回VFIO_API_VERSION（目前版本号为0）
* VFIO_CHECK_EXTENSION, ext，返回1表示支持该extension（ext），返回0表示不支持
* VFIO_SET_IOMMU, type，设置IOMMU Driver为type类型，在调用该ioctl前必须至少挂载一个VFIO Group
  * 本质上只有两种类型，即Type1 IOMMU和sPAPR IOMMU，前者代表x86、ARM等架构上的IOMMU，后者代表POWER架构上的IOMMU
  * 我们只关心Type1 IOMMU，它又细分为VFIO_TYPE1_IOMMU、VFIO_TYPE1v2_IOMMU和VFIO_TYPE1_NESTING_IOMMU，一般来说用VFIO_TYPE1v2_IOMMU即可
  * 所有的type都可以作为VFIO_CHECK_EXTENSION的参数，检查内核是否支持该类型，用户应该先检查是否支持该类型再设置IOMMU Driver

https://tcbbd.moe/linux/qemu-kvm/vfio/#Overview

## 4.2. vfio_group

当我们把一个设备直通给虚拟机时, 首先要做的就是将这个设备从 host 上进行解绑, 即**解除 host 上此设备的驱动**, 然后**将设备驱动绑定**为 "`vfio-pci`", 在完成绑定后会新增一个 `/dev/vfio/$groupid` 的文件, 其中 `$groupid` 为此 PCI 设备的 **iommu group id**, 这个 id 号是在操作系统加载 iommu driver 遍历扫描 host 上的 PCI 设备的时候就已经分配好的, 可以使用 `readlink -f /sys/bus/pci/devices/$bdf/iommu_group` 来查询. 

类似的, `/dev/vfio/$groupid` 这个文件的句柄被关联到 **vfio_group** 上, **用户态进程**打开这个文件就可以**管理这个 iommu group 里的设备**. 

```
# ll /dev/vfio/
total 0
drwxr-xr-x  2 root root       80 9月   8 02: 47 ./
drwxr-xr-x 18 root root     4580 9月   8 02: 47 ../
crw-------  1 root root 244,   0 9月   8 02: 47 21
crw-rw-rw-  1 root root  10, 196 9月   8 02: 37 vfio

# ll /sys/bus/pci/devices/0000\: 01\: 00.0/iommu_group
lrwxrwxrwx 1 root root 0 9月   8 02: 37 /sys/bus/pci/devices/0000: 01: 00.0/iommu_group -> ../. ./. ./. ./kernel/iommu_groups/21/
# readlink -f /sys/bus/pci/devices/0000\: 01\: 00.0/iommu_group
/sys/kernel/iommu_groups/21
```

## 4.3. device

然而 VFIO 中并**没有**为**每个 device** 单独创建一个文件, 而是通过 `VFIO_GROUP_GET_DEVICE_FD` 来调用这个 group ioctl 来**获取 device 的句柄**, 然后再通过这个句柄来管理设备.

## 4.4. vfio_iommu_driver

VFIO 框架中很重要的一部分是要完成 **DMA Remapping**, 即为 **Domain** 创建对应的 **IOMMU 页表**, 这个部分是由 `vfio_iommu_driver` 来完成的. 

**vfio_container** 包含一个指针记录 **vfio_iommu_driver** 的信息, 在 x86 上 `vfio_iommu_driver` 的具体实现是由 **vfio_iommu_type1** 模块来完成的.

```cpp
struct vfio_container {
        struct kref                     kref;
        struct list_head                group_list;
        struct rw_semaphore             group_lock;
        struct vfio_iommu_driver        *iommu_driver;
        void                            *iommu_data;
        bool                            noiommu;
};
```

```
│ Symbol: VFIO_IOMMU_TYPE1 [=y]
│ Type  : tristate
│ Defined at drivers/vfio/Kconfig:2
│   Depends on: VFIO [=y]
│ Selected by [y]:
│   - VFIO [=y] && MMU [=y] && (X86 [=y] || S390 || ARM || ARM64)
```

**vfio_iommu_type1** 模块包含了 `vfio_iommu`, `vfio_domain`, `vfio_group`, `vfio_dma` 等关键数据结构.

```
// drivers/vfio/vfio_iommu_type1.c
vfio_iommu : struct
vfio_domain : struct
vfio_dma : struct
vfio_batch : struct
vfio_iommu_group : struct
vfio_iova : struct
vfio_pfn : struct
vfio_regions : struct
```


* **vfio_iommu** 可以认为是和 **container** 概念相对应的 iommu 数据结构, 在虚拟化场景下**每个虚拟机的物理地址空间**映射到一个 `vfio_iommu` 上.



* **vfio_group** 可以认为是和 **group** 概念对应的 iommu 数据结构, 它指向一个 `iommu_group` 对象, 记录了着 `iommu_group` 的信息.

* **vfio_domain** 这个概念尤其需要注意, 这里绝**不能**把它理解成**一个虚拟机 domain**, 它是一个与 **DRHD**(即 IOMMU 硬件)相关的概念, 它的出现就是**为了应对多 IOMMU 硬件的场景**, 我们知道在大规格服务器上可能会有**多个 IOMMU 硬件**, 不同的 IOMMU **硬件有可能存在差异**, 例如 IOMMU 0 支持 `IOMMU_CACHE`, 而 IOMMU 1 不支持 IOMMU_CACHE(当然这种情况少见, 大部分平台上硬件功能是具备一致性的), 这时候我们**不能**直接将分别**属于不同 IOMMU 硬件管理的设备**直接加入到**一个 container** 中, 因为它们的 IOMMU 页表 SNP bit 是不一致的. 因此, 一种合理的解决办法就是把**一个 container** 划分**多个 vfio_domain**, 当然在大多数情况下我们只需要一个 vfio_domain 就足够了. 处在**同一个 vfio_domain 中的设备共享 IOMMU 页表区域**, 不同的 vfio_domain 的页表属性又可以不一致, 这样我们就可以支持跨 IOMMU 硬件的设备直通的混合场景.

```
# ll /sys/class/iommu/
total 0
drwxr-xr-x  2 root root 0 Sep 19 09: 09 ./
drwxr-xr-x 76 root root 0 Sep 19 09: 09 ../
lrwxrwxrwx  1 root root 0 Sep 19 09: 09 dmar0 -> ../. ./devices/virtual/iommu/dmar0/
lrwxrwxrwx  1 root root 0 Sep 19 09: 09 dmar1 -> ../. ./devices/virtual/iommu/dmar1/
```

## 4.5. 小结

经过上面的介绍和分析, 我们可以把 VFIO 各个组件直接的关系用下图表示.

![2021-09-18-15-43-31.png](. /images/2021-09-18-15-43-31.png)

# 5. VFIO 中的技术关键点

除了 DMA Remapping 这一关键点之外, 在虚拟化场景下 VFIO 还需要解决下面一些关键问题, 需要进行探讨:

1. VFIO 对完备的设备访问支持: 其中包括 MMIO, I/O Port, PCI 配置空间, PCI BAR 空间;
2. VFIO 中高效的设备中断机制, 其中包括 MSI/MSI-X, Interrupt Remapping, 以及 Posted Interrupt 等;
3. VFIO 对直通设备热插拔支持. 