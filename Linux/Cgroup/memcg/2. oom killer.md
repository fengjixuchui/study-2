
# 1. OOM

OOM 的全称是`out-of-memory`, 是内核在处理系统内存不足而又回收无果的情况下采取的一种措施, 内核会经过选择杀死一些进程, 以释放一些内存, 满足当前内存申请的需求.

所以oom是一种系统行为, 对应到memcg的oom, 其原理和动机跟全局oom是一样的, 区别只在于对象的不同, **全局oom**的对象是**整个系统**中**所有进程**, 而**memcg oom**只针对**memcg中的进程**(如果**使能了hierarchy**, 还包括所有**子memcg中的进程**), 这里的对象主要是指oom时内核选择从哪些进程中杀死一些进程, 所以memcg的oom**只**可能杀死**属于该memcg的进程**.

# 2. 猜测

linux 内存管理中 oom killer 机制存在于分配内存的 `__alloc_pages_slowpath()` 阶段

所以猜测 memcg 的 oom killer 机制是在 `charge`(统计计数) 阶段

# 3. 查看最初的代码

通过`tig mm/memcontrol.c`查看最开始代码, 能得到oom最初的代码

## 3.1. 相关commit

Memory controller: OOM handling, c7ba5c9e8176704bfac0729875fa62798037584d, 2008-02-07, 08:42

> oom(Out of memory)处理用于当cgroup超过其限制. 从超过限制的cgroup中拿到一个进程, 利用现有的oom逻辑kill掉这个进程.

## 3.2. 代码分析

```diff
--- a/mm/memcontrol.c
+++ b/mm/memcontrol.c
@@ -329,6 +329,7 @@ int mem_cgroup_charge(struct page *page, struct mm_struct *mm)
                }

                css_put(&mem->css);
+               mem_cgroup_out_of_memory(mem, GFP_KERNEL);
                goto free_pc;
        }
```

reset回这个commit查看当时的逻辑.

```cpp
// mm/memcontrol.c
int mem_cgroup_charge(struct page *page, struct mm_struct *mm)
{
        ......
        /*
         * If we created the page_cgroup, we should free it on exceeding
         * the cgroup limit.
         */
        // 下面逻辑都是创建了新的 page_cgroup, 即
        // 当前memcg使用的内存统计计数 + PAGE_SIZE
        // 如果大于这个memcg的limit, 则进入里面的流程
        while (res_counter_charge(&mem->res, PAGE_SIZE)) {
                // 回收释放这个memcg的page, 释放成功返回1(即进行下一次循环)
                if (try_to_free_mem_cgroup_pages(mem))
                        continue;

                /*
                 * try_to_free_mem_cgroup_pages() might not give us a full
                 * picture of reclaim. Some pages are reclaimed and might be
                 * moved to swap cache or just unmapped from the cgroup.
                 * Check the limit again to see if the reclaim reduced the
                 * current usage of the cgroup before giving up
                 */
                // 上面调用可能不会提供完整的回收信息
                // 一些页面被回收可能仅仅被移至交换缓存或仅从cgroup取消映射
                // 在放弃回收之前, 再次检查限制, 查看回收是否减少了cgroup的当前使用率
                // 在limit内返回true(下一次循环), 否则false(高于limit)
                if (res_counter_check_under_limit(&mem->res))
                        continue;
                        /*
                         * Since we control both RSS and cache, we end up with a
                         * very interesting scenario where we end up reclaiming
                         * memory (essentially RSS), since the memory is pushed
                         * to swap cache, we eventually end up adding those
                         * pages back to our list. Hence we give ourselves a
                         * few chances before we fail
                         */
                //5次的回收机会
                else if (nr_retries--) {
                        congestion_wait(WRITE, HZ/10);
                        continue;
                }

                css_put(&mem->css);
                // 回收失败则oom killer
                mem_cgroup_out_of_memory(mem, GFP_KERNEL);
                goto free_pc;
        }
        ......
}
```

**5次回收失败**则调用了`mem_cgroup_out_of_memory(mem, GFP_KERNEL);`, 

```cpp
//mm/oom_kill.c

#ifdef CONFIG_CGROUP_MEM_CONT
void mem_cgroup_out_of_memory(struct mem_cgroup *mem, gfp_t gfp_mask)
{
        unsigned long points = 0;
        struct task_struct *p;

        cgroup_lock();
        rcu_read_lock();
retry:
        // 找出该memcg下最该被kill的进程
        p = select_bad_process(&points, mem);
        if (PTR_ERR(p) == -1UL)
                goto out;
        // 没有选出, 就使用当前的
        if (!p)
                p = current;
        // 杀掉选中的进程及与其共用mm的进程
        // 杀进程的目的是释放内存, 所以当然要把mm的所有引用都干掉
        // 里面的实现会优先kill子进程
        // 不成功, 则重试
        if (oom_kill_process(p, gfp_mask, 0, points,
                                "Memory cgroup out of memory"))
                goto retry;
out:
        rcu_read_unlock();
        cgroup_unlock();
}
#endif
```

跟全局oom一样, memcg的oom也分成`select_bad_process`和`oom_kill_process`两个过程, 而这两个都直接使用了内核的函数.

这里`select_bad_process()`只不过多加了个参数, 用来**兼容memcg**.

```diff
--- a/mm/oom_kill.c
+++ b/mm/oom_kill.c
@@ -25,6 +25,7 @@
 #include <linux/cpuset.h>
 #include <linux/module.h>
 #include <linux/notifier.h>
+#include <linux/memcontrol.h>

 int sysctl_panic_on_oom;
 int sysctl_oom_kill_allocating_task;
@@ -50,7 +51,8 @@ static DEFINE_SPINLOCK(zone_scan_mutex);
  *    of least surprise ... (be careful when you change it)
  */

-unsigned long badness(struct task_struct *p, unsigned long uptime)
+unsigned long badness(struct task_struct *p, unsigned long uptime,
+                       struct mem_cgroup *mem)
 {
        unsigned long points, cpu_time, run_time, s;
        struct mm_struct *mm;
@@ -63,6 +65,13 @@ unsigned long badness(struct task_struct *p, unsigned long uptime)
                return 0;
        }
        // 关键部分
+#ifdef CONFIG_CGROUP_MEM_CONT
+       // 在memcg情况下, 如果进程mm的memcg不是当前这个, 则不处理这个进程, 返回0
+       // 确保bad进程是memcg的
+       if (mem != NULL && mm->mem_cgroup != mem) {
+               task_unlock(p);
+               return 0;
+       }
+#endif
+
        /*
         * The memory size of the process is the basis for the badness.
         */
@@ -193,7 +202,8 @@ static inline enum oom_constraint constrained_alloc(struct zonelist *zonelist,
  *
  * (not docbooked, we don't want this one cluttering up the manual)
  */
-static struct task_struct *select_bad_process(unsigned long *ppoints)
+static struct task_struct *select_bad_process(unsigned long *ppoints,
+                                               struct mem_cgroup *mem)
 {
        struct task_struct *g, *p;
        struct task_struct *chosen = NULL;
@@ -247,7 +257,7 @@ static struct task_struct *select_bad_process(unsigned long *ppoints)
                if (p->oomkilladj == OOM_DISABLE)
                        continue;

-               points = badness(p, uptime.tv_sec);
+               points = badness(p, uptime.tv_sec, mem);
                if (points > *ppoints || !chosen) {
                        chosen = p;
                        *ppoints = points;
```

跟全局oom一样, memcg的oom也分成`select_bad_process`和`oom_kill_process`两个过程:

a. `select_bad_process`会遍历系统中所有的thread, 找出该memcg下最该被kill的进程; 

b. `oom_kill_process`杀掉选中的进程及与其共用mm的进程(杀进程的目的是释放内存, 所以当然要把mm的所有引用都干掉); 

在最初的这一版中, 是直接调用内核的 `select_bad_process` 和 `oom_kill_process`.

至此第一版的memcg oom killer代码分析结束.

# 4. 最新的方案

代码版本:

```
VERSION = 5
PATCHLEVEL = 13
SUBLEVEL = 0
EXTRAVERSION = -rc1
NAME = Frozen Wasteland
```

* mm: oom: deduplicate victim selection code for memcg and global oom, 7c5f64f84483bd13886348edda8b3e7b799a7fdb
* mm: memcg: do not trap chargers with full callstack on OOM, 3812c8c8f3953921ef18544110dafc3505c1ac62
* memcg, oom: move out_of_memory back to the charge path, 29ef680ae7c21110af8e6416d84d8a72fc147b14
* memcg: killed threads should not invoke memcg OOM killer, 7775face207922ea62a4e96b9cd45abfdc7b9840
* mm, oom: fortify task_will_free_mem(), 1af8bb43269563e458ebcf0ece812e9a970864b3

```cpp
try_charge(struct mem_cgroup *memcg, gfp_t gfp_mask, unsigned int nr_pages) 
        -> mem_cgroup_oom(mem_over_limit, gfp_mask, get_order(nr_pages * PAGE_SIZE)); 
                -> mem_cgroup_out_of_memory(memcg, mask, order)
```

```cpp
// mm/memcontrol.c
static bool mem_cgroup_out_of_memory(struct mem_cgroup *memcg, gfp_t gfp_mask,
                                     int order)
{
        struct oom_control oc = {
                .zonelist = NULL,
                .nodemask = NULL,
                .memcg = memcg,
                .gfp_mask = gfp_mask,
                .order = order,
        };
        bool ret = true;
        // 拿锁成功则返回0; 返回 true 则表明获取锁失败
        if (mutex_lock_killable(&oom_lock))
                return true;
        // 
        if (mem_cgroup_margin(memcg) >= (1 << order))
                goto unlock;

        /*
         * A few threads which were not waiting at mutex_lock_killable() can
         * fail to bail out. Therefore, check again after holding oom_lock.
         */
        // 
        // current 不属于下面的几种状态, 则进行 oom
        ret = should_force_charge() || out_of_memory(&oc);

unlock:
        mutex_unlock(&oom_lock);
        return ret;
}
```

位置1的注释不是很理解那个意思, 查看相应的commit

```cpp
static inline bool should_force_charge(void)
{
        // tsk->signal->oom_mm 或
        // fatal signal pending 或
        // current 在 EXITING 状态
        return tsk_is_oom_victim(current) || fatal_signal_pending(current) ||
                (current->flags & PF_EXITING);
}
```










## select 部分

在`3.10`中, memcg实现了自己的select_bad_process, 即在memcg的代码中自己来找到要杀死的进程. 虽然函数调用不同, 但是找到要杀死的进程的原理都是类似的, select的过程会给memcg(或及其子memcg)下的**每个进程打一个分**, **得分最高者**被选中. 评分因素每个版本不尽相同, 主要会考虑以下因素: 

a. 进程**拥有page**和**swap entry越多**, 分得**越高**; 

b. 可以通过`/proc/$pid/oom_score_adj`进行一些分值干预; 

c. 拥有 `CAP_SYS_ADMIN` 的root进程分值会被调低; 


```cpp
static void select_bad_process(struct oom_control *oc)
{
        oc->chosen_points = LONG_MIN;
        // 针对oc是memcg的处理
        if (is_memcg_oom(oc))
                // 扫描, 对于task的评估通过 oom_evaluate_task
                mem_cgroup_scan_tasks(oc->memcg, oom_evaluate_task, oc);
        else {
                ......
        }
}
```

```cpp
int mem_cgroup_scan_tasks(struct mem_cgroup *memcg,
                          int (*fn)(struct task_struct *, void *), void *arg)
{
        struct mem_cgroup *iter;
        int ret = 0;
        // 如果是root memcg, oops
        BUG_ON(memcg == root_mem_cgroup);
        // 迭代这个memcg树下的所有cgroup
        for_each_mem_cgroup_tree(iter, memcg) {
                struct css_task_iter it;
                struct task_struct *task;
                // 初始化task的迭代
                css_task_iter_start(&iter->css, CSS_TASK_ITER_PROCS, &it);
                while (!ret && (task = css_task_iter_next(&it)))
                        ret = fn(task, arg);
                // 
                css_task_iter_end(&it);
                if (ret) {
                        mem_cgroup_iter_break(memcg, iter);
                        break;
                }
        }
        return ret;
}
```

对于task的评估使用 `oom_evaluate_task`, 和kernel原本方法一样



## kill 部分


kill的过程比较简单, 简单的说就是向要杀死的进程发送SIGKILL信号, 但其中依然有一些细节: 

a. 如果被选中的进程有一些子进程跟他不共用同一个mm, 并且也是可以被杀死的, 那么就挑选这些子进程中badness得分最高的一个来代替父进程被杀死, 这样是为了确保我们在释放内存的同时失去更少的东西; 

b. 上面已经说了, oom_kill的过程会杀死选中的进程及与其共用mm的进程, 所以会遍历所有用户态进程, 找到并杀死与选中进程共用同一个mm的进程; 

c. 遍历进程的过程中, 会过滤掉通过`/proc/$pid/oom_score_adj`干预的不可被oom_kill掉的进程(目前是设置为OOM_SCORE_ADJ_MIN的进程); 

在oom的过程中, 另外值得一说的是其中的同步过程. 

oom过程会向选中的进程发送SIGKILL信号, 但是距离进程处理信号、释放空间, 还是需要经历一定时间的. 如果系统负载较高, 则这段时间内很可能有其他上下文也需要却得不到page, 而触发新的oom. 那么如果大量oom在短时间内爆发, 可能会大面积杀死系统中的进程, 带来一场浩劫. 

所以oom过程需要同步: 在给选中的进程发送SIGKILL后, 会设置其TIF_MEMDIE标记. 而在select被杀死进程的过程中如果发现记有TIF_MEMDIE的进程, 则终止当前的oom过程, 并等待上一个oom过程结束. 这样做可以避免oom时大面积的kill进程. 

而在进程退出时, 会先将task->mm置为NULL, 再mmput(mm)释放掉引用计数, 从而导致内存空间被释放(如果引用计数减为0的话). 所以, 只要task->mm被置为NULL(内存即将开始释放), 就没人认得它是属于哪个memcg的了, 针对那个memcg的新的oom过程就可以开始. 


### oom.group

mm, oom: introduce memory.oom.group, 3d8b38eb81cac81395f6a823f6bf401b327268e6, Tue Aug 21 21:53:54 2018

```cpp
struct mem_cgroup *mem_cgroup_get_oom_group(struct task_struct *victim,
                                            struct mem_cgroup *oom_domain)
{
        struct mem_cgroup *oom_group = NULL;
        struct mem_cgroup *memcg;

#ifndef CONFIG_MEM_QOS
        if (!cgroup_subsys_on_dfl(memory_cgrp_subsys))
                return NULL;
#endif

        // oc->memcg 没有
        if (!oom_domain)
                oom_domain = root_mem_cgroup;

        rcu_read_lock();

        memcg = mem_cgroup_from_task(victim);
        if (memcg == root_mem_cgroup)
                goto out;

        /*
         * Traverse the memory cgroup hierarchy from the victim task's
         * cgroup up to the OOMing cgroup (or root) to find the
         * highest-level memory cgroup with oom.group set.
         */
        // 一直往上层找, 一直到 oc->memcg/root(约束), 结果是最高层的oom_group为1的
        for (; memcg; memcg = parent_mem_cgroup(memcg)) {
                if (memcg->oom_group)
                        oom_group = memcg;

                if (memcg == oom_domain)
                        break;
        }

        if (oom_group)
                css_get(&oom_group->css);
out:
        rcu_read_unlock();

        return oom_group;
}
```

```
  /sys/fs/cgroup/memory(根/)
          /   \
         /     \
       cg0    cg1
       /  \    
      /    \   
   0-0-0  0-0-1


```






```cpp
// 
static int try_charge(struct mem_cgroup *memcg, gfp_t gfp_mask,
                      unsigned int nr_pages)
{
        ......
retry:
        /*
         * keep retrying as long as the memcg oom killer is able to make
         * a forward progress or bypass the charge if the oom killer
         * couldn't make any progress.
         */
        // 只要memcg oom Killer能够取得前进, 就可以持续重试
        // 如果oom killer无法取得任何进展, 则绕开charge.
        oom_status = mem_cgroup_oom(mem_over_limit, gfp_mask,
                       get_order(nr_pages * PAGE_SIZE));
        switch (oom_status) {
        case OOM_SUCCESS:
                // oom成功, 持续重试
                nr_retries = MAX_RECLAIM_RETRIES;
                goto retry;
        case OOM_FAILED:
                // oom失败
                // 强制charge, 暂时会超过limit
                goto force;
        default:
                goto nomem;
        }
nomem:
        if (!(gfp_mask & __GFP_NOFAIL))
                return -ENOMEM;
force:
        /*
         * The allocation either can't fail or will lead to more memory
         * being freed very soon.  Allow memory usage go over the limit
         * temporarily by force charging it.
         */
        // 分配要么不会失败, 要么会导致很快释放更多的内存
        // 通过强制charge使内存使用量暂时超过限制
        page_counter_charge(&memcg->memory, nr_pages);
        if (do_memsw_account())
                page_counter_charge(&memcg->memsw, nr_pages);

        return 0;
        ......
```








# 5. 

通过`struct mem_cgroup`中oom相关的结构体变量以及`mm/memcontrol.c`中相关变量(`memcg_oom_mutex`等), 查找最初的memcg oom killer代码

> 因为结构体位置有变化(从`mm/memcontrol.c`到了`include/linux/memcontrol.h`), 以及代码覆盖情况(时间太久了), 所以有过多次reset动作

先是关注`struct mem_cgroup`的变量, 如下

```cpp
struct mem_cgroup {
    /* OOM-Killer disable */
    int             oom_kill_disable;

    /* For oom notifier event fd */
    struct list_head oom_notify;
}
```

得到最终patch set, 2010-05-26, 14:42

* memcg: oom wakeup filter, dc98df5a1b7be402a0e1c71f1b89ccf249ac15ee
* memcg: oom notifier, 9490ff275606da012d5b373342a49610ad61cb81
* memcg: oom kill disable and oom status, 3c11ecf448eff8f12922c498b8274ce98587eb74

但是查看git show 





* memcg: fix oom kill behavior, 867578cbccb0893cc14fc29c670f7185809c90d6, 2010-03-10 15:22

























最终代码:
* arch: mm: remove obsolete init OOM protection, 94bce453c78996cc4373d5da6cfabe07fcc6d9f9
* arch: mm: do not invoke OOM killer on kernel fault OOM, 871341023c771ad233620b7a1fb3d9c7031c4e5c
* arch: mm: pass userspace fault flag to generic fault handler, 759496ba6407c6994d6a5ce3a5e74937d7816208
* x86: finish user fault error path with fatal signal, 3a13c4d761b4b979ba8767f42345fed3274991b0
* mm: memcg: enable memcg OOM killer only for user faults, 519e52473ebe9db5cdef44670d5a97f1fd53d721
* mm: memcg: rework and document OOM waiting and wakeup, fb2a6fc56be66c169f8b80e07ed999ba453a2db2
* mm: memcg: do not trap chargers with full callstack on OOM, 3812c8c8f3953921ef18544110dafc3505c1ac62




improve memcg oom killer robustness (提升memcg oom killer的健壮性)

* v1
    * patch set: https://lkml.org/lkml/2013/7/25/653 , 
    * lwn: https://lwn.net/Articles/560868/

* v2
    * patch set: https://lore.kernel.org/lkml/1375549200-19110-1-git-send-email-hannes@cmpxchg.org/ , https://lkml.org/lkml/2013/8/3/81 , 
    * lwn: https://lwn.net/Articles/562091/


第一版代码分析

在分配内存失败的情况下, memcg代码会导致task trap, 直到解决OOM情况为止. 此时, 它们可以持有各种锁(fs, mm), 这容易导致死锁. 

此系列patch将memcg OOM处理转换为在charge上下文中启动的两步过程, 但是在完全解开错误堆栈后将进行任何等待. 

1-4为支持新的memcg要求的体系结构处理程序做准备, 但是这样做还可以消除旧的残废并统一整个体系结构的内存不足行为. 

补丁5禁用了针对系统调用, 预读, 内核故障的memcg OOM处理, 因为它们可以使用-ENOMEM正常展开堆栈.  OOM处理仅限于没有其他选择的用户触发的故障. 

补丁6实现了由两部分组成的OOM处理, 以使任务永远不会在OOM情况下被充满电荷的堆栈所困. 








最终代码:

* 

* mm: memcg: enable memcg OOM killer only for user faults: 519e52473ebe9db5cdef44670d5a97f1fd53d721


# memcg priority oom killer

## ali 方案


https://github.com/alibaba/cloud-kernel/commit/52e375fcb7a71d62566dc89764ce107e2f6af9ee#diff-8fa1dddd53606ceb933c5c6a12e714ed41e11d37a2b7bc48e91d15b54171d033



在内存压力下, 将发生回收和oom. 在一个有多个cgroup的系统中, 当有其他候选时, 我们可能需要这些cgroup的一些内存或任务在回收和oom中幸存下来. 

@memory.low 和 @memory.min已在回收期间发生这种情况, 此补丁引入了memcg优先级oom来满足oom中的上述要求. 

优先级是从0到12, 数字越高优先级越高.  当oom发生时, 它总是从低优先级的memcg中选择受害者. 它既适用于memcg oom, 也适用于全局oom, 可以通过 `@memory.use_priority_oom` 启用/禁用, 对于通过**根memcg**的 `@memory.use_priority_oom` 进行的全局缩放, 默认情况下处于禁用状态. 



每个mem_cgroup结构体引入了几个和memcg priority的变量

```diff
@@ -252,6 +255,12 @@ struct mem_cgroup {
	bool		oom_lock;
	int		under_oom;

	/* memcg priority */
	bool use_priority_oom;
	int priority;
	int num_oom_skip;
	struct mem_cgroup *next_reset;

	int	swappiness;
```

原有逻辑也是调用kernel 的 `out_of_memory()`, 然后调用`select_bad_process`和`oom_kill_process`

在原有逻辑中, `select_bad_process`阶段, 如果是memcg, 进行调用memcg自己的函数`mem_cgroup_scan_tasks`

新方案, 如果oom_control是memcg或者`root_memcg_use_priority_oom()` root_memcg 使用priority_oom, 则调用自己实现的`mem_cgroup_select_bad_process(oc);`

>注: 所以可能在内存分配上下文(即非memcg的charge阶段), 可能也会调用到memcg的select bad process; 
> 而在select中, 如果是内存page分配上下文(oc->memcg为空), 则`memcg = root_mem_cgroup`;

如果memcg(可能是当前memcg`<在charge上下文>`或root_memcg)使用了`priority_oom`, 先调用`mem_cgroup_select_victim_cgroup()`选择一个受害者memcgroup, 然后调用之前的`mem_cgroup_scan_tasks`从这个受害者memcgroup中扫描进程(以前方案只有在memcg charge上下文会发生, 所以只会当前memcg的扫描task)

>注: 
>新方案只要开启root_memcg的priority_oom都会调用mem_cgroup的scan_tasks方法? 是否合理
>如果当前memcg没有开启priority_oom, 则也不会根据priority选择mem_cgroup


> task_struct->css_set->cgroup_subsys_state->cgroup

在`mem_cgroup_select_victim_cgroup()`中, 
1. 如果这个memcg没有hierarchy, 则返回当前memcg
2. 获得memcg的subsystem(parent)
3. 获得parent css的memcg(parent_memcg)
4. while(parent)

- 如果parent的task数目小于等于 其对应的memcg不可kill的task数目(num_oom_skip), 跳出循环
- 受害者等于parent
- chosen_priority = 12 + 1 (最高优先级+1)
- 遍历parent subsystem的children(子链表串)css
        - 如果子css的task数目小于等于 其对应的memcg不可kill的task数目(num_oom_skip), 下一个子css
        - 子css的memcg的priority大于chosen_priority, 下一个子css



## 我的方案









mm: memcg: do not trap chargers with full callstack on OOM: 3812c8c8f3953921ef18544110dafc3505c1ac62

[RFC PATCH] memcg, oom: move out_of_memory back to the charge path: https://www.mail-archive.com/linux-kernel@vger.kernel.org/msg1716129.html

memcg, oom: move out_of_memory back to the charge path, 29ef680ae7c21110af8e6416d84d8a72fc147b14


# 参考

内核oom过程简单分析, http://0fd.org/2015/06/11/the-memory-cgroup-oom-process/