
DMA实际上是赋予了设备在 CPU 的控制下, 对 memory 进行读写访问的的能力.

* "CPU的控制", 指的是控制路径, CPU/软件当然要对DMA的地址、长度进行设置, 对不同的设备的DMA空间进行隔离等;
* 而实际的DMA动作, 则是by pass CPU的.

谈到DMA, 不可避免的会涉及到不同的地址转换, 这对理解Linux下面的DMA是十分重要的. 总共有三类地址: 虚拟地址, 物理地址以及总线地址.

内核通常使用虚拟地址, 比如像kmallc(), vmalloc()和类似的接口返回的地址都是`void *`类型的虚拟地址.

虚拟内存系统, 比如TLB, 页表等, 会将虚拟地址转换成CPU的物理地址. 物理地址的类型一般为`phy_addr_t`或者`resource_size_t`. 外设的寄存器, 内核实际上是把它们当成物理地址来进行管理, 这些地址可以在`/proc/iomem`中被访问. 这些物理地址不能直接被驱动程序使用, 必须使用ioremap()来将这些地址映射为虚拟地址之后, 才能被驱动所使用. 这也就是为什么我们的驱动程序中, 总是会看到设备的寄存器地址空间被ioremap后, 才能被正确访问.

对于 IO 设备来讲, 它们使用的地址通常被称为总线地址(bus address). 如果设备的寄存器在MMIO地址空间, 或者设备使用DMA对memory进行读写访问, 这个过程中设备所使用的地址其实就是总线地址. 在一些硬件架构中, 总线地址和CPU的物理地址是相同的, 但是并不是所有的都这样. IOMMU和host bridge可以在总线地址和物理地址之间进行任意的映射.

> x86 中 物理地址 = 总线地址

从设备的角度来讲, DMA使用总线地址空间或者总线地址空间的一个子集. 比如说, 虽然系统支持64-bit的地址空间, 但是经过IOMMU, 设备可能仅仅使用32-bit的地址空间就可以了.

![2021-09-27-18-05-05.png](./images/2021-09-27-18-05-05.png)

在枚举过程中, 内核会获取到IO设备、它们的MMIO空间以及所挂载的桥设备. 例如, 一个PCI设备有BAR空间, 内核从BAR空间中拿到总线地址(A), 并且将它转换成CPU物理地址(B). 地址(B)被存储在struct resource结构中, 并且通过/proc/iomem暴露出来. 当驱动probe设备的时候, 通常会用ioremap()来讲物理地址(B)映射成虚拟地址(C). 此时, 就可以通过类似ioread32(C)来访问到设备在总线地址(A)上的寄存器.

驱动程序同样的, 可以使用kmalloc()和类似的接口, 来分配一个buffer. 接口返回的地址实际上是虚拟地址, 如虚拟地址(X). 虚拟内存系统将X映射到物理地址(Y). 驱动可以使用虚拟地址(X)来访问这个buffer, 但是设备不能使用这个地址, 因为DMA不会经过CPU的虚拟内存系统.

在一些简单的系统中, 设备可以直接向屋里地址Y进行DMA访问. 但是在其他的系统中, 一般需要一种硬件, 比如IOMMU, 建立DMA地址(总线地址)和物理地址的映射关系. 比如, 将地址(Z)转换成地址(Y). dma_map_single()接口其实就是做了这么一个事情: 传入了虚拟地址X, 然后设置IOMMU映射, 然后返回了总线地址(DMA地址)Z. 映射之后, 驱动就可以告诉设备使用地址(Z)进行DMA, IOMMU会将对这个地址的DMA操作映射到实际的RAM中的地址Y上.

Linux系统也能支持动态DMA映射, 驱动只需要在地址实际使用之前进行mapping, 在使用之后进行unmap即可.

DMA相关的API

DMA相关的API与底层的架构无关, 因为Linux已经替我们做好了HAL层. 所以我们使用DMA API的使用, 不应该使用总线相关的API, 比如使用dma_map_(), 而非pci_map_()接口.

在我们的驱动程序里, 应该包含头文件linux/dma-mapping.h, 这个头文件提供了dma_addr_t的定义. dma_addr_t可以提供对任何平台的dma地址的支持.

# 内存的DMA可用性

哪些内存可以被用作DMA？有一些不成文的规则.

使用页面分配函数(比如__get_gree_page*())或者通用内存分配函数(比如kmalloc()、kmem_cache_alloc())分配的地址一般是可以来用作DMA地址的.

而使用 `vmallc()` 函数分配的地址最好不要用作DMA, 因为vmalloc分配出来的地址在物理地址上不一定连续, 进行DMA的时候可能需要遍历页表去拿到物理地址, 而将这些物理地址转成虚拟地址的时候, 又需要使用到__va()类似的函数.

所以, 我们一般不能使用内核镜像地址(比如 `data/text/bss` 段), 或者模块镜像地址、栈地址来进行DMA, 这些地址可能被映射到物理内存上的任意位置. 即使我们要使用这些种类的地址来进行DMA, 我们也需要确保I/O buffer是cacheline对齐的. 否则, 就很容易在DMA-incoherent cache上出现cache一致性的问题.

我们也不能使用kmap()返回的地址来进行DMA, 原因与vmalloc()类似.

块I/O和网络设备的buffer怎么分配的呢？实际上, 块I/O和网络子系统会保证它们使用的地址是可以进行DMA的.

# DMA地址的限制

设备对于DMA地址空间一般都有一定的限制, 比如说我们的设备的寻址能力只有24bit, 那么我们一定要将限制通知到内核.

默认情况下, 内核认为设备的寻址空间可以达到32bit. 对于有64bit寻址能力的设备来讲, 我们需要告知内核调大这个能力. 而对于不足32bit寻址能力的设备来讲, 需要告诉内核降低这个能力.

需要特别注意的一点是: PCI-X规范要求PCI-X设备要能够支持64-bit的寻址(DAC)的数据传输. 并且某些平台(SGI SN2)也要求当IO总线是PCI-X模式时, 必须要支持64bit的consistent分配.

正确的操作应该是: 我们必须在设备的probe函数中向内核查询机器的DMA控制器能否正常支持当前设备的DMA寻址限制. 即使设备支持默认的设置, 我们最好也在probe函数中这么做. 起码说明我们考虑到了这个事情.

通过调用dma_set_mask_and_coherent()可以完成这种能力通知: 函数原型为

